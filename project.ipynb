{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_learning_projeto_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZGrXe0jmDBB"
      },
      "source": [
        "# Depêndencias iniciais\n",
        "Iremos agora importar as principais bibliotecas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-CfjT-kltv5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "import json\n",
        "import os\n",
        "import glob"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDbR65d8mkI-"
      },
      "source": [
        "# O dataset\n",
        "Nessa primeira parte, iremos carregar o _dataset_ na estrutura de dados que utilizaremos, que será o [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIt2sny_FSmk"
      },
      "source": [
        "# Lendo arquivo CSV\n",
        "filename = '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/fer2013.csv'\n",
        "df = pd.read_csv(filename)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZsoV7Kgm9U9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab6b081-9652-4deb-ea1d-37bb6f52a671"
      },
      "source": [
        "# Conhecendo a quantidade de linhas e colunas do dataset, respectivamente\n",
        "print(\"dataset:= \", df.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset:=  (35887, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s74oMYPhm9pX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be480193-f4d3-440f-bda1-52559a7cae67"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['emotion', 'pixels', 'Usage'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSZAOhW_mobG"
      },
      "source": [
        "## Explorando o dataset\n",
        "Aqui iremos utilizar alguns métodos do pandas para conhecermos melhor o nosso _DataFrame_. Os métodos serão:\n",
        "- **[head](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html)**: mostra as primeiras _n_ linhas do nosso _dataset_. Por padrão serão as 5 primeiras linhas.\n",
        "- **[info](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html)**: imprime informações sobre o nosso _DataFrame_, incluindo o tipo de índice, os tipos de coluna, valores não nulos e uso de memória.\n",
        "\n",
        "- **[describe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)**: mostra estatísticas descritivas sobre as colunas do nosso _DataFrame_, como: a tendência central, a dispersão e a forma da distribuição de um conjunto de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGC8uVwVldab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "fb31b522-77af-485d-92f3-b8ce0b5fc8a2"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     Usage\n",
              "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
              "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
              "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
              "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
              "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H05qqekkpmrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c527d768-036d-4266-f499-572de57dad69"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35887 entries, 0 to 35886\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   emotion  35887 non-null  int64 \n",
            " 1   pixels   35887 non-null  object\n",
            " 2   Usage    35887 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 841.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4eKiVVCpmkH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "4ae75861-0624-434a-84a3-e75fe4a05a2f"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35887.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.323265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.873819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            emotion\n",
              "count  35887.000000\n",
              "mean       3.323265\n",
              "std        1.873819\n",
              "min        0.000000\n",
              "25%        2.000000\n",
              "50%        3.000000\n",
              "75%        5.000000\n",
              "max        6.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqtqCCQM2OOb"
      },
      "source": [
        "# Modelos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejBK6uSjayhh"
      },
      "source": [
        "X_train, train_y, X_test, test_y = [], [], [], []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    val = row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "            X_train.append(np.array(val, 'float32'))\n",
        "            train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "            X_test.append(np.array(val, 'float32'))\n",
        "            test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")\n",
        "\n",
        "num_labels = 7\n",
        "width, height = 48, 48\n",
        "\n",
        "X_train = np.array(X_train, 'float32')\n",
        "train_y = np.array(train_y, 'float32')\n",
        "X_test = np.array(X_test, 'float32')\n",
        "test_y = np.array(test_y, 'float32')\n",
        "\n",
        "train_y = np_utils.to_categorical(train_y, num_classes=num_labels)\n",
        "test_y = np_utils.to_categorical(test_y, num_classes=num_labels)\n",
        "\n",
        "X_train -= np.mean(X_train, axis=0)\n",
        "X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhvebTdEfNJ0"
      },
      "source": [
        "models = {}"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRIj3S0zc3Mn"
      },
      "source": [
        "## Convolutional Neural Networks for Facial Expression Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPL1vscAmSgh"
      },
      "source": [
        "class ShallowCNN(tf.keras.models.Sequential):\n",
        "    def __init__(self, input_shape, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1st Convolutional Layer\n",
        "        self.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), input_shape=(input_shape)))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.25))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        # 2nd Convolutional Layer\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1)))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.25))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        # Flattening\n",
        "        self.add(tf.keras.layers.Flatten())\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.add(tf.keras.layers.Dense(512))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "        self.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "        self.add(tf.keras.layers.Dense(num_labels, activation='softmax'))\n",
        "\n",
        "\n",
        "models['ShallowCNN'] = ShallowCNN(X_train.shape[1:], num_labels)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdzE3AlXfBWk"
      },
      "source": [
        "class DeepCNN(tf.keras.models.Sequential):\n",
        "    def __init__(self, input_shape, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1st Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), input_shape=(input_shape)))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.25))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        # 2nd Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(5, 5), strides=(1, 1)))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.25))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        # 3rd Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1)))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.25))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        # 4th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1)))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.25))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        # Flattening\n",
        "        self.add(tf.keras.layers.Flatten())\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.add(tf.keras.layers.Dense(256))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.25))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        # Fully connected layer 2nd layer\n",
        "        self.add(tf.keras.layers.Dense(512))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.25))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        self.add(tf.keras.layers.Dense(num_labels, activation='softmax'))\n",
        "\n",
        "\n",
        "models['DeepCNN'] = DeepCNN(X_train.shape[1:], num_labels)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lk4Ggj5ZQqz"
      },
      "source": [
        "## (Custom) Convolutional Neural Networks for Facial Expression Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAdaYNpYZQqz"
      },
      "source": [
        "class DeepCNNCustom(tf.keras.models.Sequential):\n",
        "    def __init__(self, input_shape, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1st Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), input_shape=(input_shape)))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        # 2nd Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(5, 5), strides=(1, 1)))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        # 2nd Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1)))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        # 3rd Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1)))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.3))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        # 4th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.3))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        # Flattening\n",
        "        self.add(tf.keras.layers.Flatten())\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.add(tf.keras.layers.Dense(256))\n",
        "        #self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        # Fully connected layer 2nd layer\n",
        "        self.add(tf.keras.layers.Dense(512))\n",
        "        #self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        self.add(tf.keras.layers.Dense(num_labels, activation='softmax'))\n",
        "\n",
        "\n",
        "models['DeepCNNCustom'] = DeepCNNCustom(X_train.shape[1:], num_labels)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX7nH1jdfrE0"
      },
      "source": [
        "## Very Deep Convolutional Networks for Large-Scale Image Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXk1h1uWfrE_"
      },
      "source": [
        "class VGGA11(tf.keras.models.Sequential):\n",
        "    def __init__(self, input_shape, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1st Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(input_shape)))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 2nd Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 3rd Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 4th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 5th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.add(tf.keras.layers.Flatten())\n",
        "        self.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dense(num_labels, activation='softmax'))\n",
        "\n",
        "\n",
        "models['VGGA11'] = VGGA11(X_train.shape[1:], num_labels)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNYXguo1frFA"
      },
      "source": [
        "class VGGALRN11(tf.keras.models.Sequential):\n",
        "    def __init__(self, input_shape, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1st Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(input_shape)))\n",
        "        self.add(tf.keras.layers.LayerNormalization())\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 2nd Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 3rd Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 4th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 5th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.add(tf.keras.layers.Flatten())\n",
        "        self.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dense(num_labels, activation='softmax'))\n",
        "\n",
        "\n",
        "models['VGGALRN11'] = VGGALRN11(X_train.shape[1:], num_labels)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIuxyUWdgUz9"
      },
      "source": [
        "class VGGB13(tf.keras.models.Sequential):\n",
        "    def __init__(self, input_shape, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1st Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(input_shape)))\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 2nd Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 3rd Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 4th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 5th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.add(tf.keras.layers.Flatten())\n",
        "        self.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dense(num_labels, activation='softmax'))\n",
        "\n",
        "\n",
        "models['VGGB13'] = VGGB13(X_train.shape[1:], num_labels)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNa6__XCgUwr"
      },
      "source": [
        "class VGGC16(tf.keras.models.Sequential):\n",
        "    def __init__(self, input_shape, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1st Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(input_shape), padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 2nd Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 3rd Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(1, 1), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 4th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(1, 1), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 5th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(1, 1), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.add(tf.keras.layers.Flatten())\n",
        "        self.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dense(num_labels, activation='softmax'))\n",
        "\n",
        "\n",
        "models['VGGC16'] = VGGC16(X_train.shape[1:], num_labels)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSv9CXTrgUtK"
      },
      "source": [
        "class VGGD16(tf.keras.models.Sequential):\n",
        "    def __init__(self, input_shape, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1st Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(input_shape), padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 2nd Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 3rd Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 4th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 5th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.add(tf.keras.layers.Flatten())\n",
        "        self.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dense(num_labels, activation='softmax'))\n",
        "\n",
        "\n",
        "models['VGGD16'] = VGGD16(X_train.shape[1:], num_labels)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alefit_rgUpK"
      },
      "source": [
        "class VGGE19(tf.keras.models.Sequential):\n",
        "    def __init__(self, input_shape, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1st Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(input_shape)))\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 2nd Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 3rd Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 4th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 5th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.add(tf.keras.layers.Flatten())\n",
        "        self.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dense(num_labels, activation='softmax'))\n",
        "\n",
        "\n",
        "models['VGGE19'] = VGGE19(X_train.shape[1:], num_labels)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIX4ALAPZy8g"
      },
      "source": [
        "## (Custom) Very Deep Convolutional Networks for Large-Scale Image Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo1x0qNRe9dQ"
      },
      "source": [
        "class VGGCustom(tf.keras.models.Sequential):\n",
        "    def __init__(self, input_shape, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1st Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(input_shape)))\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        self.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "        # 2nd Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        self.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "        # 3rd Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.add(tf.keras.layers.Flatten())\n",
        "        self.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.add(tf.keras.layers.Dense(num_labels, activation='softmax'))\n",
        "\n",
        "\n",
        "models['VGGCustom'] = VGGCustom(X_train.shape[1:], num_labels)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmHGrhUrZy8v"
      },
      "source": [
        "class VGGE19Custom(tf.keras.models.Sequential):\n",
        "    def __init__(self, input_shape, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1st Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(input_shape)))\n",
        "        self.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 2nd Conv Block\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(5, 5), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 3rd Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(5, 5), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 4th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(5, 5), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # 5th Conv block\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(5, 5), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        self.add(tf.keras.layers.BatchNormalization())\n",
        "        self.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.add(tf.keras.layers.Flatten())\n",
        "        self.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "        self.add(tf.keras.layers.Dense(num_labels, activation='softmax'))\n",
        "\n",
        "\n",
        "models['VGGE19Custom'] = VGGE19Custom(X_train.shape[1:], num_labels)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqdRMvKcfZV1"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_bMxs5kg-_1",
        "outputId": "c7a81670-dd7c-4049-a1fc-2d321382c430"
      },
      "source": [
        "models"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DeepCNN': <__main__.DeepCNN at 0x7f3f4da86be0>,\n",
              " 'DeepCNNCustom': <__main__.DeepCNNCustom at 0x7f3fc010b320>,\n",
              " 'ShallowCNN': <__main__.ShallowCNN at 0x7f3f4dd167f0>,\n",
              " 'VGGA11': <__main__.VGGA11 at 0x7f3f6c1c0e10>,\n",
              " 'VGGALRN11': <__main__.VGGALRN11 at 0x7f3f4da27358>,\n",
              " 'VGGB13': <__main__.VGGB13 at 0x7f3f4d995a20>,\n",
              " 'VGGC16': <__main__.VGGC16 at 0x7f3f4d9028d0>,\n",
              " 'VGGD16': <__main__.VGGD16 at 0x7f3f4d8f5550>,\n",
              " 'VGGD16Custom': <__main__.VGGD16Custom at 0x7f3f4d98a9e8>,\n",
              " 'VGGE19': <__main__.VGGE19 at 0x7f3f4d878160>,\n",
              " 'VGGE19Custom': <__main__.VGGE19Custom at 0x7f3f4d7ba5f8>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-BmYwV3fBWl",
        "outputId": "fde54641-20ad-4b5e-c134-c25a443a728b"
      },
      "source": [
        "for model in models.values():\n",
        "  print(model.summary())\n",
        "  print(\"\\n-------------------------------------\\n\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"shallow_cnn_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_26 (Conv2D)           (None, 46, 46, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 46, 46, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 46, 46, 32)        0         \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 46, 46, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 44, 44, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 44, 44, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 44, 44, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 30976)             0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 512)               15860224  \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 7)                 3591      \n",
            "=================================================================\n",
            "Total params: 15,885,063\n",
            "Trainable params: 15,883,847\n",
            "Non-trainable params: 1,216\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Model: \"deep_cnn_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 46, 46, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 46, 46, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 46, 46, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 19, 19, 128)       204928    \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 19, 19, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 19, 19, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 7, 7, 512)         590336    \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 1, 1, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 1, 1, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 7)                 3591      \n",
            "=================================================================\n",
            "Total params: 3,430,151\n",
            "Trainable params: 3,426,183\n",
            "Non-trainable params: 3,968\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Model: \"deep_cnn_custom_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_32 (Conv2D)           (None, 46, 46, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 46, 46, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 46, 46, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "activation_41 (Activation)   (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 19, 19, 128)       204928    \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 19, 19, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 19, 19, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 7, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 1, 1, 512)         590336    \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 1, 1, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 1, 1, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 1, 1, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "activation_45 (Activation)   (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "activation_46 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 7)                 3591      \n",
            "=================================================================\n",
            "Total params: 3,575,175\n",
            "Trainable params: 3,572,487\n",
            "Non-trainable params: 2,688\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Model: \"vgg_a11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_37 (Conv2D)           (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 4096)              8392704   \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 7)                 28679     \n",
            "=================================================================\n",
            "Total params: 34,422,023\n",
            "Trainable params: 34,422,023\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Model: \"vggalr_n11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_45 (Conv2D)           (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "layer_normalization (LayerNo (None, 48, 48, 64)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 4096)              8392704   \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 7)                 28679     \n",
            "=================================================================\n",
            "Total params: 34,422,151\n",
            "Trainable params: 34,422,151\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Model: \"vgg_b13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_53 (Conv2D)           (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 4096)              8392704   \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 7)                 28679     \n",
            "=================================================================\n",
            "Total params: 34,606,535\n",
            "Trainable params: 34,606,535\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Model: \"vgg_c16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_63 (Conv2D)           (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_48 (MaxPooling (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_66 (Conv2D)           (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_49 (MaxPooling (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_67 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_68 (Conv2D)           (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_69 (Conv2D)           (None, 12, 12, 256)       65792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_50 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_71 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_72 (Conv2D)           (None, 6, 6, 512)         262656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_51 (MaxPooling (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_73 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_74 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_75 (Conv2D)           (None, 3, 3, 512)         262656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_52 (MaxPooling (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 4096)              8392704   \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 7)                 28679     \n",
            "=================================================================\n",
            "Total params: 35,197,639\n",
            "Trainable params: 35,197,639\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Model: \"vgg_d16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_76 (Conv2D)           (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_82 (Conv2D)           (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_55 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_83 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_84 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_85 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_86 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_87 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_88 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_57 (MaxPooling (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 4096)              8392704   \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 7)                 28679     \n",
            "=================================================================\n",
            "Total params: 39,916,231\n",
            "Trainable params: 39,916,231\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Model: \"vgg_e19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_89 (Conv2D)           (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_90 (Conv2D)           (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_58 (MaxPooling (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_91 (Conv2D)           (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_92 (Conv2D)           (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_59 (MaxPooling (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_93 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_94 (Conv2D)           (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_95 (Conv2D)           (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_96 (Conv2D)           (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_60 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_97 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_98 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_99 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_100 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_61 (MaxPooling (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_101 (Conv2D)          (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_102 (Conv2D)          (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_103 (Conv2D)          (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_104 (Conv2D)          (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_62 (MaxPooling (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 4096)              8392704   \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 7)                 28679     \n",
            "=================================================================\n",
            "Total params: 45,225,927\n",
            "Trainable params: 45,225,927\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Model: \"vgg_e19custom\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_105 (Conv2D)          (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_106 (Conv2D)          (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_63 (MaxPooling (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_107 (Conv2D)          (None, 24, 24, 128)       204928    \n",
            "_________________________________________________________________\n",
            "conv2d_108 (Conv2D)          (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_64 (MaxPooling (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_109 (Conv2D)          (None, 12, 12, 256)       819456    \n",
            "_________________________________________________________________\n",
            "conv2d_110 (Conv2D)          (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_111 (Conv2D)          (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_112 (Conv2D)          (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_65 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_113 (Conv2D)          (None, 6, 6, 512)         3277312   \n",
            "_________________________________________________________________\n",
            "conv2d_114 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_115 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_116 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_48 (Batc (None, 6, 6, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_66 (MaxPooling (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_117 (Conv2D)          (None, 3, 3, 512)         6554112   \n",
            "_________________________________________________________________\n",
            "conv2d_118 (Conv2D)          (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_119 (Conv2D)          (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_120 (Conv2D)          (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_49 (Batc (None, 3, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_67 (MaxPooling (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 4096)              8392704   \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 7)                 7175      \n",
            "=================================================================\n",
            "Total params: 39,571,143\n",
            "Trainable params: 39,568,199\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Model: \"vgg_d16custom\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_121 (Conv2D)          (None, 46, 46, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_122 (Conv2D)          (None, 44, 44, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_68 (MaxPooling (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_123 (Conv2D)          (None, 20, 20, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_124 (Conv2D)          (None, 18, 18, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_69 (MaxPooling (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_125 (Conv2D)          (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_126 (Conv2D)          (None, 5, 5, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_70 (MaxPooling (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_53 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 7)                 7175      \n",
            "=================================================================\n",
            "Total params: 1,914,951\n",
            "Trainable params: 1,914,951\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "-------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gu8YGbv2gzu"
      },
      "source": [
        "dirname = '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models'\n",
        "\n",
        "def save_model(model, name, BATCH_SIZE, EPOCHS, hist):\n",
        "    fer_json = model.to_json()\n",
        "\n",
        "    with open('{}/{}_{}_{}.json'.format(dirname, name, BATCH_SIZE, EPOCHS), 'w') as json_file:\n",
        "        json_file.write(fer_json)\n",
        "    model.save_weights('{}/{}_{}_{}.h5'.format(dirname, name, BATCH_SIZE, EPOCHS))\n",
        "\n",
        "    with open('{}/hist_{}_{}_{}.json'.format(dirname, name, BATCH_SIZE, EPOCHS), 'w') as json_file:\n",
        "        json.dump(hist, json_file)\n",
        "    \n",
        "\n",
        "def check_model_exists(name, BATCH_SIZE, EPOCHS):\n",
        "    return os.path.exists('{}/{}_{}_{}.json'.format(dirname, name, BATCH_SIZE, EPOCHS))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLsWxVJT8zVd"
      },
      "source": [
        "from keras import backend as keras_backend\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = keras_backend.sum(keras_backend.round(keras_backend.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = keras_backend.sum(keras_backend.round(keras_backend.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + keras_backend.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = keras_backend.sum(keras_backend.round(keras_backend.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = keras_backend.sum(keras_backend.round(keras_backend.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + keras_backend.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_metrics(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+keras_backend.epsilon()))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgrfcsLSfBWl",
        "outputId": "7568aa2c-856f-4a90-8c11-94b161d32b5e"
      },
      "source": [
        "# Training the model\n",
        "for name, model in models.items():\n",
        "  print(\"\\n-------------------------------------\\n\")\n",
        "  model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\n",
        "                tf.keras.metrics.Accuracy(name='accuracy'),\n",
        "                tf.keras.metrics.Precision(name='precision'),\n",
        "                tf.keras.metrics.Recall(name='recall'),\n",
        "                f1_metrics,\n",
        "                #'accuracy',\n",
        "                #precision_m,\n",
        "                #recall_m,\n",
        "              ])\n",
        "  \n",
        "  for BATCH_SIZE in [128, 256]:\n",
        "    for EPOCHS in [30, 50, 100]:\n",
        "      print(\"{} | batch_size: {} | epochs: {}\".format(name, BATCH_SIZE, EPOCHS))\n",
        "\n",
        "      if check_model_exists(name, BATCH_SIZE, EPOCHS):\n",
        "        continue\n",
        "\n",
        "      hist = model.fit(X_train, train_y,\n",
        "                batch_size=BATCH_SIZE,\n",
        "                epochs=EPOCHS,\n",
        "                verbose=1,\n",
        "                validation_data=(X_test, test_y),\n",
        "                shuffle=True\n",
        "              )\n",
        "      \n",
        "      model_hist = {\n",
        "          'id': '{}_{}_{}'.format(name, BATCH_SIZE, EPOCHS),\n",
        "          'name': name,\n",
        "          'metrics': {\n",
        "              'loss': hist.history['loss'][-1],\n",
        "              'val_loss': hist.history['val_loss'][-1],\n",
        "              'accuracy': hist.history['accuracy'][-1],\n",
        "              'val_accuracy': hist.history['val_accuracy'][-1],\n",
        "              'f1_metrics': hist.history['f1_metrics'][-1],\n",
        "              'val_f1_metrics': hist.history['val_f1_metrics'][-1],\n",
        "              'precision': hist.history['precision'][-1],\n",
        "              'val_precision': hist.history['val_precision'][-1],\n",
        "              'recall': hist.history['recall'][-1],\n",
        "              'val_recall': hist.history['val_recall'][-1],\n",
        "          },\n",
        "          'params': {\n",
        "              'batch_size': BATCH_SIZE,\n",
        "              'epochs': EPOCHS,\n",
        "              'steps': hist.params['steps'],\n",
        "          }\n",
        "      }\n",
        "  \n",
        "      save_model(model, name, BATCH_SIZE, EPOCHS, model_hist)\n",
        "      #break\n",
        "    #break\n",
        "  #break\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------------------------------------\n",
            "\n",
            "ShallowCNN | batch_size: 128 | epochs: 30\n",
            "ShallowCNN | batch_size: 128 | epochs: 50\n",
            "ShallowCNN | batch_size: 128 | epochs: 100\n",
            "ShallowCNN | batch_size: 256 | epochs: 30\n",
            "ShallowCNN | batch_size: 256 | epochs: 50\n",
            "ShallowCNN | batch_size: 256 | epochs: 100\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "DeepCNN | batch_size: 128 | epochs: 30\n",
            "DeepCNN | batch_size: 128 | epochs: 50\n",
            "DeepCNN | batch_size: 128 | epochs: 100\n",
            "DeepCNN | batch_size: 256 | epochs: 30\n",
            "DeepCNN | batch_size: 256 | epochs: 50\n",
            "DeepCNN | batch_size: 256 | epochs: 100\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "DeepCNNCustom | batch_size: 128 | epochs: 30\n",
            "DeepCNNCustom | batch_size: 128 | epochs: 50\n",
            "DeepCNNCustom | batch_size: 128 | epochs: 100\n",
            "DeepCNNCustom | batch_size: 256 | epochs: 30\n",
            "DeepCNNCustom | batch_size: 256 | epochs: 50\n",
            "DeepCNNCustom | batch_size: 256 | epochs: 100\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "VGGA11 | batch_size: 128 | epochs: 30\n",
            "VGGA11 | batch_size: 128 | epochs: 50\n",
            "VGGA11 | batch_size: 128 | epochs: 100\n",
            "VGGA11 | batch_size: 256 | epochs: 30\n",
            "VGGA11 | batch_size: 256 | epochs: 50\n",
            "VGGA11 | batch_size: 256 | epochs: 100\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "VGGALRN11 | batch_size: 128 | epochs: 30\n",
            "VGGALRN11 | batch_size: 128 | epochs: 50\n",
            "VGGALRN11 | batch_size: 128 | epochs: 100\n",
            "VGGALRN11 | batch_size: 256 | epochs: 30\n",
            "VGGALRN11 | batch_size: 256 | epochs: 50\n",
            "VGGALRN11 | batch_size: 256 | epochs: 100\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "VGGB13 | batch_size: 128 | epochs: 30\n",
            "VGGB13 | batch_size: 128 | epochs: 50\n",
            "VGGB13 | batch_size: 128 | epochs: 100\n",
            "VGGB13 | batch_size: 256 | epochs: 30\n",
            "VGGB13 | batch_size: 256 | epochs: 50\n",
            "VGGB13 | batch_size: 256 | epochs: 100\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "VGGC16 | batch_size: 128 | epochs: 30\n",
            "VGGC16 | batch_size: 128 | epochs: 50\n",
            "VGGC16 | batch_size: 128 | epochs: 100\n",
            "VGGC16 | batch_size: 256 | epochs: 30\n",
            "VGGC16 | batch_size: 256 | epochs: 50\n",
            "VGGC16 | batch_size: 256 | epochs: 100\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "VGGD16 | batch_size: 128 | epochs: 30\n",
            "VGGD16 | batch_size: 128 | epochs: 50\n",
            "VGGD16 | batch_size: 128 | epochs: 100\n",
            "VGGD16 | batch_size: 256 | epochs: 30\n",
            "VGGD16 | batch_size: 256 | epochs: 50\n",
            "VGGD16 | batch_size: 256 | epochs: 100\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "VGGE19 | batch_size: 128 | epochs: 30\n",
            "VGGE19 | batch_size: 128 | epochs: 50\n",
            "VGGE19 | batch_size: 128 | epochs: 100\n",
            "VGGE19 | batch_size: 256 | epochs: 30\n",
            "VGGE19 | batch_size: 256 | epochs: 50\n",
            "VGGE19 | batch_size: 256 | epochs: 100\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "VGGE19Custom | batch_size: 128 | epochs: 30\n",
            "VGGE19Custom | batch_size: 128 | epochs: 50\n",
            "VGGE19Custom | batch_size: 128 | epochs: 100\n",
            "VGGE19Custom | batch_size: 256 | epochs: 30\n",
            "VGGE19Custom | batch_size: 256 | epochs: 50\n",
            "VGGE19Custom | batch_size: 256 | epochs: 100\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "VGGD16Custom | batch_size: 128 | epochs: 30\n",
            "Epoch 1/30\n",
            "225/225 [==============================] - 8s 34ms/step - loss: 1.7415 - accuracy: 0.0000e+00 - precision: 0.6209 - recall: 0.0292 - f1_metrics: 0.0505 - val_loss: 1.5942 - val_accuracy: 0.0000e+00 - val_precision: 0.6914 - val_recall: 0.1349 - val_f1_metrics: 0.2174\n",
            "Epoch 2/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 1.5186 - accuracy: 0.0000e+00 - precision: 0.7229 - recall: 0.1634 - f1_metrics: 0.2644 - val_loss: 1.3944 - val_accuracy: 0.0000e+00 - val_precision: 0.7756 - val_recall: 0.2129 - val_f1_metrics: 0.3327\n",
            "Epoch 3/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 1.3996 - accuracy: 0.0000e+00 - precision: 0.7407 - recall: 0.2222 - f1_metrics: 0.3402 - val_loss: 1.3181 - val_accuracy: 0.0000e+00 - val_precision: 0.7447 - val_recall: 0.2650 - val_f1_metrics: 0.3866\n",
            "Epoch 4/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 1.3179 - accuracy: 0.0000e+00 - precision: 0.7407 - recall: 0.2640 - f1_metrics: 0.3874 - val_loss: 1.2714 - val_accuracy: 0.0000e+00 - val_precision: 0.7124 - val_recall: 0.3374 - val_f1_metrics: 0.4496\n",
            "Epoch 5/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 1.2680 - accuracy: 0.0000e+00 - precision: 0.7433 - recall: 0.2944 - f1_metrics: 0.4196 - val_loss: 1.2318 - val_accuracy: 0.0000e+00 - val_precision: 0.7416 - val_recall: 0.3207 - val_f1_metrics: 0.4413\n",
            "Epoch 6/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 1.2291 - accuracy: 0.0000e+00 - precision: 0.7469 - recall: 0.3159 - f1_metrics: 0.4431 - val_loss: 1.1993 - val_accuracy: 0.0000e+00 - val_precision: 0.7608 - val_recall: 0.3332 - val_f1_metrics: 0.4563\n",
            "Epoch 7/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 1.1959 - accuracy: 0.0000e+00 - precision: 0.7406 - recall: 0.3378 - f1_metrics: 0.4624 - val_loss: 1.1763 - val_accuracy: 0.0000e+00 - val_precision: 0.7738 - val_recall: 0.3335 - val_f1_metrics: 0.4591\n",
            "Epoch 8/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 1.1588 - accuracy: 0.0000e+00 - precision: 0.7459 - recall: 0.3591 - f1_metrics: 0.4837 - val_loss: 1.1886 - val_accuracy: 0.0000e+00 - val_precision: 0.7576 - val_recall: 0.3405 - val_f1_metrics: 0.4624\n",
            "Epoch 9/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 1.1394 - accuracy: 0.0000e+00 - precision: 0.7477 - recall: 0.3734 - f1_metrics: 0.4972 - val_loss: 1.1507 - val_accuracy: 0.0000e+00 - val_precision: 0.7675 - val_recall: 0.3422 - val_f1_metrics: 0.4660\n",
            "Epoch 10/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 1.1111 - accuracy: 0.0000e+00 - precision: 0.7524 - recall: 0.3880 - f1_metrics: 0.5109 - val_loss: 1.1728 - val_accuracy: 0.0000e+00 - val_precision: 0.7519 - val_recall: 0.3631 - val_f1_metrics: 0.4818\n",
            "Epoch 11/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 1.0870 - accuracy: 0.0000e+00 - precision: 0.7516 - recall: 0.4049 - f1_metrics: 0.5252 - val_loss: 1.1517 - val_accuracy: 0.0000e+00 - val_precision: 0.7278 - val_recall: 0.4157 - val_f1_metrics: 0.5187\n",
            "Epoch 12/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 1.0670 - accuracy: 4.9760e-06 - precision: 0.7576 - recall: 0.4157 - f1_metrics: 0.5358 - val_loss: 1.1601 - val_accuracy: 0.0000e+00 - val_precision: 0.7000 - val_recall: 0.4174 - val_f1_metrics: 0.5199\n",
            "Epoch 13/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 1.0440 - accuracy: 0.0000e+00 - precision: 0.7566 - recall: 0.4335 - f1_metrics: 0.5501 - val_loss: 1.1750 - val_accuracy: 0.0000e+00 - val_precision: 0.7327 - val_recall: 0.3918 - val_f1_metrics: 0.5023\n",
            "Epoch 14/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 1.0283 - accuracy: 9.9521e-06 - precision: 0.7616 - recall: 0.4411 - f1_metrics: 0.5577 - val_loss: 1.1647 - val_accuracy: 0.0000e+00 - val_precision: 0.7100 - val_recall: 0.4257 - val_f1_metrics: 0.5306\n",
            "Epoch 15/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 1.0080 - accuracy: 4.9760e-06 - precision: 0.7642 - recall: 0.4568 - f1_metrics: 0.5709 - val_loss: 1.1346 - val_accuracy: 0.0000e+00 - val_precision: 0.7396 - val_recall: 0.4051 - val_f1_metrics: 0.5219\n",
            "Epoch 16/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.9848 - accuracy: 9.9521e-06 - precision: 0.7644 - recall: 0.4731 - f1_metrics: 0.5836 - val_loss: 1.1278 - val_accuracy: 0.0000e+00 - val_precision: 0.7284 - val_recall: 0.4132 - val_f1_metrics: 0.5173\n",
            "Epoch 17/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.9634 - accuracy: 4.9760e-06 - precision: 0.7634 - recall: 0.4829 - f1_metrics: 0.5910 - val_loss: 1.1305 - val_accuracy: 0.0000e+00 - val_precision: 0.7221 - val_recall: 0.4221 - val_f1_metrics: 0.5309\n",
            "Epoch 18/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.9403 - accuracy: 2.4880e-05 - precision: 0.7725 - recall: 0.4989 - f1_metrics: 0.6056 - val_loss: 1.1444 - val_accuracy: 0.0000e+00 - val_precision: 0.7185 - val_recall: 0.4558 - val_f1_metrics: 0.5555\n",
            "Epoch 19/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.9238 - accuracy: 9.9521e-06 - precision: 0.7697 - recall: 0.5102 - f1_metrics: 0.6132 - val_loss: 1.1505 - val_accuracy: 0.0000e+00 - val_precision: 0.7179 - val_recall: 0.4544 - val_f1_metrics: 0.5541\n",
            "Epoch 20/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.9045 - accuracy: 2.4880e-05 - precision: 0.7742 - recall: 0.5230 - f1_metrics: 0.6239 - val_loss: 1.1303 - val_accuracy: 0.0000e+00 - val_precision: 0.7162 - val_recall: 0.4620 - val_f1_metrics: 0.5593\n",
            "Epoch 21/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.8828 - accuracy: 7.4641e-05 - precision: 0.7801 - recall: 0.5347 - f1_metrics: 0.6338 - val_loss: 1.1553 - val_accuracy: 3.9804e-05 - val_precision: 0.7157 - val_recall: 0.4558 - val_f1_metrics: 0.5601\n",
            "Epoch 22/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.8594 - accuracy: 7.4641e-05 - precision: 0.7826 - recall: 0.5511 - f1_metrics: 0.6463 - val_loss: 1.1577 - val_accuracy: 3.9804e-05 - val_precision: 0.6970 - val_recall: 0.4659 - val_f1_metrics: 0.5477\n",
            "Epoch 23/30\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.8462 - accuracy: 9.4545e-05 - precision: 0.7833 - recall: 0.5609 - f1_metrics: 0.6534 - val_loss: 1.1943 - val_accuracy: 7.9608e-05 - val_precision: 0.6946 - val_recall: 0.4695 - val_f1_metrics: 0.5560\n",
            "Epoch 24/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.8312 - accuracy: 9.9521e-05 - precision: 0.7864 - recall: 0.5703 - f1_metrics: 0.6603 - val_loss: 1.1883 - val_accuracy: 3.9804e-05 - val_precision: 0.7066 - val_recall: 0.4717 - val_f1_metrics: 0.5559\n",
            "Epoch 25/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.8107 - accuracy: 8.9569e-05 - precision: 0.7924 - recall: 0.5847 - f1_metrics: 0.6721 - val_loss: 1.1781 - val_accuracy: 0.0000e+00 - val_precision: 0.6915 - val_recall: 0.4684 - val_f1_metrics: 0.5468\n",
            "Epoch 26/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.7847 - accuracy: 5.9712e-05 - precision: 0.7948 - recall: 0.5975 - f1_metrics: 0.6817 - val_loss: 1.2347 - val_accuracy: 3.9804e-05 - val_precision: 0.6776 - val_recall: 0.4848 - val_f1_metrics: 0.5536\n",
            "Epoch 27/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.7793 - accuracy: 1.7416e-04 - precision: 0.7984 - recall: 0.6078 - f1_metrics: 0.6894 - val_loss: 1.1973 - val_accuracy: 7.9608e-05 - val_precision: 0.6991 - val_recall: 0.4804 - val_f1_metrics: 0.5652\n",
            "Epoch 28/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.7479 - accuracy: 1.3933e-04 - precision: 0.8036 - recall: 0.6188 - f1_metrics: 0.6986 - val_loss: 1.2687 - val_accuracy: 1.9902e-04 - val_precision: 0.6718 - val_recall: 0.5013 - val_f1_metrics: 0.5695\n",
            "Epoch 29/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.7536 - accuracy: 2.3885e-04 - precision: 0.8024 - recall: 0.6212 - f1_metrics: 0.6999 - val_loss: 1.2242 - val_accuracy: 2.7863e-04 - val_precision: 0.6867 - val_recall: 0.4812 - val_f1_metrics: 0.5601\n",
            "Epoch 30/30\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.7229 - accuracy: 2.6373e-04 - precision: 0.8043 - recall: 0.6355 - f1_metrics: 0.7100 - val_loss: 1.2511 - val_accuracy: 2.3882e-04 - val_precision: 0.6893 - val_recall: 0.5082 - val_f1_metrics: 0.5800\n",
            "VGGD16Custom | batch_size: 128 | epochs: 50\n",
            "Epoch 1/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.7070 - accuracy: 3.5330e-04 - precision: 0.8089 - recall: 0.6448 - f1_metrics: 0.7173 - val_loss: 1.2579 - val_accuracy: 7.9608e-05 - val_precision: 0.6714 - val_recall: 0.4896 - val_f1_metrics: 0.5539\n",
            "Epoch 2/50\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.6841 - accuracy: 4.4287e-04 - precision: 0.8181 - recall: 0.6632 - f1_metrics: 0.7323 - val_loss: 1.2898 - val_accuracy: 2.7863e-04 - val_precision: 0.6707 - val_recall: 0.4982 - val_f1_metrics: 0.5600\n",
            "Epoch 3/50\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.6826 - accuracy: 4.3789e-04 - precision: 0.8156 - recall: 0.6645 - f1_metrics: 0.7322 - val_loss: 1.2680 - val_accuracy: 7.9608e-05 - val_precision: 0.6821 - val_recall: 0.4968 - val_f1_metrics: 0.5629\n",
            "Epoch 4/50\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.6608 - accuracy: 4.6277e-04 - precision: 0.8189 - recall: 0.6771 - f1_metrics: 0.7411 - val_loss: 1.3273 - val_accuracy: 3.1843e-04 - val_precision: 0.6669 - val_recall: 0.4971 - val_f1_metrics: 0.5586\n",
            "Epoch 5/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.6508 - accuracy: 6.5186e-04 - precision: 0.8248 - recall: 0.6856 - f1_metrics: 0.7487 - val_loss: 1.3852 - val_accuracy: 1.9902e-04 - val_precision: 0.6460 - val_recall: 0.5035 - val_f1_metrics: 0.5552\n",
            "Epoch 6/50\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.6346 - accuracy: 5.8220e-04 - precision: 0.8244 - recall: 0.6969 - f1_metrics: 0.7546 - val_loss: 1.3368 - val_accuracy: 2.7863e-04 - val_precision: 0.6639 - val_recall: 0.5052 - val_f1_metrics: 0.5616\n",
            "Epoch 7/50\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.6171 - accuracy: 4.7770e-04 - precision: 0.8262 - recall: 0.7017 - f1_metrics: 0.7588 - val_loss: 1.3463 - val_accuracy: 1.9902e-04 - val_precision: 0.6646 - val_recall: 0.5107 - val_f1_metrics: 0.5657\n",
            "Epoch 8/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.6046 - accuracy: 6.1703e-04 - precision: 0.8329 - recall: 0.7114 - f1_metrics: 0.7674 - val_loss: 1.3619 - val_accuracy: 1.1941e-04 - val_precision: 0.6558 - val_recall: 0.5138 - val_f1_metrics: 0.5704\n",
            "Epoch 9/50\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.6009 - accuracy: 7.4143e-04 - precision: 0.8332 - recall: 0.7168 - f1_metrics: 0.7703 - val_loss: 1.4067 - val_accuracy: 4.3785e-04 - val_precision: 0.6583 - val_recall: 0.5191 - val_f1_metrics: 0.5676\n",
            "Epoch 10/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.5908 - accuracy: 0.0010 - precision: 0.8339 - recall: 0.7186 - f1_metrics: 0.7715 - val_loss: 1.3735 - val_accuracy: 2.3882e-04 - val_precision: 0.6586 - val_recall: 0.5171 - val_f1_metrics: 0.5682\n",
            "Epoch 11/50\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.5710 - accuracy: 0.0010 - precision: 0.8400 - recall: 0.7299 - f1_metrics: 0.7806 - val_loss: 1.3946 - val_accuracy: 3.9804e-04 - val_precision: 0.6504 - val_recall: 0.5230 - val_f1_metrics: 0.5671\n",
            "Epoch 12/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.5603 - accuracy: 0.0012 - precision: 0.8437 - recall: 0.7398 - f1_metrics: 0.7879 - val_loss: 1.4110 - val_accuracy: 4.7765e-04 - val_precision: 0.6467 - val_recall: 0.5166 - val_f1_metrics: 0.5626\n",
            "Epoch 13/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.5523 - accuracy: 0.0012 - precision: 0.8446 - recall: 0.7419 - f1_metrics: 0.7894 - val_loss: 1.3872 - val_accuracy: 4.3785e-04 - val_precision: 0.6578 - val_recall: 0.5216 - val_f1_metrics: 0.5771\n",
            "Epoch 14/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.5387 - accuracy: 0.0013 - precision: 0.8464 - recall: 0.7458 - f1_metrics: 0.7926 - val_loss: 1.4072 - val_accuracy: 4.7765e-04 - val_precision: 0.6533 - val_recall: 0.5213 - val_f1_metrics: 0.5677\n",
            "Epoch 15/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.5329 - accuracy: 0.0013 - precision: 0.8515 - recall: 0.7544 - f1_metrics: 0.7995 - val_loss: 1.4210 - val_accuracy: 5.1745e-04 - val_precision: 0.6459 - val_recall: 0.5149 - val_f1_metrics: 0.5610\n",
            "Epoch 16/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.5171 - accuracy: 0.0014 - precision: 0.8537 - recall: 0.7587 - f1_metrics: 0.8032 - val_loss: 1.4541 - val_accuracy: 9.9510e-04 - val_precision: 0.6499 - val_recall: 0.5244 - val_f1_metrics: 0.5683\n",
            "Epoch 17/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.5123 - accuracy: 0.0015 - precision: 0.8538 - recall: 0.7646 - f1_metrics: 0.8067 - val_loss: 1.5018 - val_accuracy: 6.7667e-04 - val_precision: 0.6364 - val_recall: 0.5219 - val_f1_metrics: 0.5674\n",
            "Epoch 18/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.5051 - accuracy: 0.0015 - precision: 0.8541 - recall: 0.7679 - f1_metrics: 0.8084 - val_loss: 1.5061 - val_accuracy: 9.9510e-04 - val_precision: 0.6386 - val_recall: 0.5205 - val_f1_metrics: 0.5617\n",
            "Epoch 19/50\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.4944 - accuracy: 0.0018 - precision: 0.8577 - recall: 0.7759 - f1_metrics: 0.8145 - val_loss: 1.5058 - val_accuracy: 5.1745e-04 - val_precision: 0.6349 - val_recall: 0.5224 - val_f1_metrics: 0.5609\n",
            "Epoch 20/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.4817 - accuracy: 0.0017 - precision: 0.8638 - recall: 0.7847 - f1_metrics: 0.8221 - val_loss: 1.5517 - val_accuracy: 7.5628e-04 - val_precision: 0.6365 - val_recall: 0.5339 - val_f1_metrics: 0.5759\n",
            "Epoch 21/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.4825 - accuracy: 0.0016 - precision: 0.8621 - recall: 0.7868 - f1_metrics: 0.8222 - val_loss: 1.4861 - val_accuracy: 6.7667e-04 - val_precision: 0.6417 - val_recall: 0.5230 - val_f1_metrics: 0.5719\n",
            "Epoch 22/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.4739 - accuracy: 0.0015 - precision: 0.8649 - recall: 0.7869 - f1_metrics: 0.8237 - val_loss: 1.5609 - val_accuracy: 7.5628e-04 - val_precision: 0.6280 - val_recall: 0.5249 - val_f1_metrics: 0.5595\n",
            "Epoch 23/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.4627 - accuracy: 0.0020 - precision: 0.8665 - recall: 0.7940 - f1_metrics: 0.8284 - val_loss: 1.5608 - val_accuracy: 8.7569e-04 - val_precision: 0.6337 - val_recall: 0.5408 - val_f1_metrics: 0.5774\n",
            "Epoch 24/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.4625 - accuracy: 0.0019 - precision: 0.8665 - recall: 0.7925 - f1_metrics: 0.8275 - val_loss: 1.5704 - val_accuracy: 8.3589e-04 - val_precision: 0.6375 - val_recall: 0.5425 - val_f1_metrics: 0.5866\n",
            "Epoch 25/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.4454 - accuracy: 0.0023 - precision: 0.8708 - recall: 0.8040 - f1_metrics: 0.8360 - val_loss: 1.5910 - val_accuracy: 9.9510e-04 - val_precision: 0.6265 - val_recall: 0.5286 - val_f1_metrics: 0.5691\n",
            "Epoch 26/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.4457 - accuracy: 0.0024 - precision: 0.8694 - recall: 0.8031 - f1_metrics: 0.8350 - val_loss: 1.5566 - val_accuracy: 8.7569e-04 - val_precision: 0.6352 - val_recall: 0.5414 - val_f1_metrics: 0.5816\n",
            "Epoch 27/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.4415 - accuracy: 0.0024 - precision: 0.8722 - recall: 0.8060 - f1_metrics: 0.8379 - val_loss: 1.5764 - val_accuracy: 0.0011 - val_precision: 0.6438 - val_recall: 0.5383 - val_f1_metrics: 0.5834\n",
            "Epoch 28/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.4332 - accuracy: 0.0027 - precision: 0.8732 - recall: 0.8104 - f1_metrics: 0.8403 - val_loss: 1.5634 - val_accuracy: 0.0014 - val_precision: 0.6372 - val_recall: 0.5389 - val_f1_metrics: 0.5728\n",
            "Epoch 29/50\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.4352 - accuracy: 0.0022 - precision: 0.8733 - recall: 0.8102 - f1_metrics: 0.8404 - val_loss: 1.5227 - val_accuracy: 0.0010 - val_precision: 0.6398 - val_recall: 0.5336 - val_f1_metrics: 0.5701\n",
            "Epoch 30/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.4216 - accuracy: 0.0027 - precision: 0.8778 - recall: 0.8161 - f1_metrics: 0.8455 - val_loss: 1.6110 - val_accuracy: 0.0013 - val_precision: 0.6344 - val_recall: 0.5347 - val_f1_metrics: 0.5693\n",
            "Epoch 31/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.4188 - accuracy: 0.0031 - precision: 0.8763 - recall: 0.8170 - f1_metrics: 0.8456 - val_loss: 1.5426 - val_accuracy: 0.0013 - val_precision: 0.6405 - val_recall: 0.5347 - val_f1_metrics: 0.5708\n",
            "Epoch 32/50\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.4123 - accuracy: 0.0029 - precision: 0.8778 - recall: 0.8205 - f1_metrics: 0.8481 - val_loss: 1.5792 - val_accuracy: 0.0016 - val_precision: 0.6345 - val_recall: 0.5467 - val_f1_metrics: 0.5760\n",
            "Epoch 33/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.4143 - accuracy: 0.0028 - precision: 0.8797 - recall: 0.8190 - f1_metrics: 0.8481 - val_loss: 1.5935 - val_accuracy: 0.0012 - val_precision: 0.6296 - val_recall: 0.5375 - val_f1_metrics: 0.5741\n",
            "Epoch 34/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3985 - accuracy: 0.0031 - precision: 0.8826 - recall: 0.8267 - f1_metrics: 0.8537 - val_loss: 1.6191 - val_accuracy: 9.1550e-04 - val_precision: 0.6342 - val_recall: 0.5453 - val_f1_metrics: 0.5801\n",
            "Epoch 35/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3890 - accuracy: 0.0037 - precision: 0.8853 - recall: 0.8335 - f1_metrics: 0.8585 - val_loss: 1.6495 - val_accuracy: 0.0013 - val_precision: 0.6281 - val_recall: 0.5430 - val_f1_metrics: 0.5705\n",
            "Epoch 36/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3828 - accuracy: 0.0036 - precision: 0.8854 - recall: 0.8358 - f1_metrics: 0.8596 - val_loss: 1.7075 - val_accuracy: 0.0020 - val_precision: 0.6250 - val_recall: 0.5439 - val_f1_metrics: 0.5698\n",
            "Epoch 37/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3789 - accuracy: 0.0043 - precision: 0.8887 - recall: 0.8390 - f1_metrics: 0.8630 - val_loss: 1.6453 - val_accuracy: 8.7569e-04 - val_precision: 0.6178 - val_recall: 0.5364 - val_f1_metrics: 0.5633\n",
            "Epoch 38/50\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.3832 - accuracy: 0.0035 - precision: 0.8867 - recall: 0.8366 - f1_metrics: 0.8605 - val_loss: 1.6268 - val_accuracy: 9.1550e-04 - val_precision: 0.6298 - val_recall: 0.5414 - val_f1_metrics: 0.5776\n",
            "Epoch 39/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3753 - accuracy: 0.0034 - precision: 0.8885 - recall: 0.8394 - f1_metrics: 0.8630 - val_loss: 1.6801 - val_accuracy: 0.0012 - val_precision: 0.6301 - val_recall: 0.5534 - val_f1_metrics: 0.5845\n",
            "Epoch 40/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3641 - accuracy: 0.0035 - precision: 0.8940 - recall: 0.8472 - f1_metrics: 0.8698 - val_loss: 1.6354 - val_accuracy: 0.0011 - val_precision: 0.6250 - val_recall: 0.5428 - val_f1_metrics: 0.5683\n",
            "Epoch 41/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3835 - accuracy: 0.0031 - precision: 0.8842 - recall: 0.8374 - f1_metrics: 0.8599 - val_loss: 1.6183 - val_accuracy: 0.0011 - val_precision: 0.6306 - val_recall: 0.5495 - val_f1_metrics: 0.5823\n",
            "Epoch 42/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3630 - accuracy: 0.0038 - precision: 0.8927 - recall: 0.8475 - f1_metrics: 0.8694 - val_loss: 1.6184 - val_accuracy: 0.0013 - val_precision: 0.6261 - val_recall: 0.5403 - val_f1_metrics: 0.5682\n",
            "Epoch 43/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3531 - accuracy: 0.0044 - precision: 0.8944 - recall: 0.8502 - f1_metrics: 0.8713 - val_loss: 1.7614 - val_accuracy: 0.0020 - val_precision: 0.6287 - val_recall: 0.5581 - val_f1_metrics: 0.5782\n",
            "Epoch 44/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3585 - accuracy: 0.0039 - precision: 0.8928 - recall: 0.8498 - f1_metrics: 0.8707 - val_loss: 1.6430 - val_accuracy: 0.0014 - val_precision: 0.6284 - val_recall: 0.5433 - val_f1_metrics: 0.5713\n",
            "Epoch 45/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3535 - accuracy: 0.0035 - precision: 0.8968 - recall: 0.8532 - f1_metrics: 0.8741 - val_loss: 1.6940 - val_accuracy: 0.0019 - val_precision: 0.6219 - val_recall: 0.5517 - val_f1_metrics: 0.5799\n",
            "Epoch 46/50\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.3554 - accuracy: 0.0038 - precision: 0.8933 - recall: 0.8510 - f1_metrics: 0.8715 - val_loss: 1.6467 - val_accuracy: 0.0012 - val_precision: 0.6200 - val_recall: 0.5391 - val_f1_metrics: 0.5658\n",
            "Epoch 47/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3422 - accuracy: 0.0039 - precision: 0.8984 - recall: 0.8570 - f1_metrics: 0.8768 - val_loss: 1.6795 - val_accuracy: 0.0013 - val_precision: 0.6173 - val_recall: 0.5419 - val_f1_metrics: 0.5654\n",
            "Epoch 48/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3463 - accuracy: 0.0039 - precision: 0.8969 - recall: 0.8566 - f1_metrics: 0.8762 - val_loss: 1.7362 - val_accuracy: 0.0018 - val_precision: 0.6227 - val_recall: 0.5514 - val_f1_metrics: 0.5736\n",
            "Epoch 49/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3329 - accuracy: 0.0043 - precision: 0.9000 - recall: 0.8618 - f1_metrics: 0.8803 - val_loss: 1.7124 - val_accuracy: 0.0019 - val_precision: 0.6263 - val_recall: 0.5514 - val_f1_metrics: 0.5891\n",
            "Epoch 50/50\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3434 - accuracy: 0.0052 - precision: 0.8971 - recall: 0.8587 - f1_metrics: 0.8771 - val_loss: 1.7264 - val_accuracy: 0.0025 - val_precision: 0.6206 - val_recall: 0.5397 - val_f1_metrics: 0.5654\n",
            "VGGD16Custom | batch_size: 128 | epochs: 100\n",
            "Epoch 1/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3288 - accuracy: 0.0043 - precision: 0.9024 - recall: 0.8628 - f1_metrics: 0.8819 - val_loss: 1.7639 - val_accuracy: 0.0032 - val_precision: 0.6278 - val_recall: 0.5522 - val_f1_metrics: 0.5761\n",
            "Epoch 2/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3309 - accuracy: 0.0051 - precision: 0.8995 - recall: 0.8631 - f1_metrics: 0.8810 - val_loss: 1.7678 - val_accuracy: 0.0020 - val_precision: 0.6273 - val_recall: 0.5528 - val_f1_metrics: 0.5816\n",
            "Epoch 3/100\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.3373 - accuracy: 0.0048 - precision: 0.9006 - recall: 0.8615 - f1_metrics: 0.8805 - val_loss: 1.7566 - val_accuracy: 0.0021 - val_precision: 0.6267 - val_recall: 0.5525 - val_f1_metrics: 0.5811\n",
            "Epoch 4/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3229 - accuracy: 0.0050 - precision: 0.9043 - recall: 0.8680 - f1_metrics: 0.8857 - val_loss: 1.8006 - val_accuracy: 0.0024 - val_precision: 0.6278 - val_recall: 0.5550 - val_f1_metrics: 0.5844\n",
            "Epoch 5/100\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.3247 - accuracy: 0.0054 - precision: 0.9044 - recall: 0.8651 - f1_metrics: 0.8842 - val_loss: 1.7836 - val_accuracy: 0.0023 - val_precision: 0.6177 - val_recall: 0.5456 - val_f1_metrics: 0.5747\n",
            "Epoch 6/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3136 - accuracy: 0.0058 - precision: 0.9055 - recall: 0.8713 - f1_metrics: 0.8883 - val_loss: 1.8277 - val_accuracy: 0.0023 - val_precision: 0.6260 - val_recall: 0.5559 - val_f1_metrics: 0.5824\n",
            "Epoch 7/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3202 - accuracy: 0.0052 - precision: 0.9034 - recall: 0.8675 - f1_metrics: 0.8849 - val_loss: 1.8220 - val_accuracy: 0.0022 - val_precision: 0.6150 - val_recall: 0.5469 - val_f1_metrics: 0.5744\n",
            "Epoch 8/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3242 - accuracy: 0.0055 - precision: 0.9029 - recall: 0.8671 - f1_metrics: 0.8845 - val_loss: 1.7341 - val_accuracy: 0.0023 - val_precision: 0.6198 - val_recall: 0.5414 - val_f1_metrics: 0.5753\n",
            "Epoch 9/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3141 - accuracy: 0.0060 - precision: 0.9071 - recall: 0.8718 - f1_metrics: 0.8889 - val_loss: 1.8451 - val_accuracy: 0.0025 - val_precision: 0.6155 - val_recall: 0.5545 - val_f1_metrics: 0.5707\n",
            "Epoch 10/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3122 - accuracy: 0.0068 - precision: 0.9089 - recall: 0.8738 - f1_metrics: 0.8909 - val_loss: 1.8085 - val_accuracy: 0.0030 - val_precision: 0.6166 - val_recall: 0.5525 - val_f1_metrics: 0.5767\n",
            "Epoch 11/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3172 - accuracy: 0.0055 - precision: 0.9065 - recall: 0.8721 - f1_metrics: 0.8892 - val_loss: 1.8142 - val_accuracy: 0.0029 - val_precision: 0.6240 - val_recall: 0.5539 - val_f1_metrics: 0.5820\n",
            "Epoch 12/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3159 - accuracy: 0.0056 - precision: 0.9057 - recall: 0.8733 - f1_metrics: 0.8891 - val_loss: 1.7415 - val_accuracy: 0.0019 - val_precision: 0.6326 - val_recall: 0.5556 - val_f1_metrics: 0.5854\n",
            "Epoch 13/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3041 - accuracy: 0.0057 - precision: 0.9096 - recall: 0.8776 - f1_metrics: 0.8935 - val_loss: 1.7715 - val_accuracy: 0.0027 - val_precision: 0.6226 - val_recall: 0.5561 - val_f1_metrics: 0.5813\n",
            "Epoch 14/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2993 - accuracy: 0.0062 - precision: 0.9105 - recall: 0.8790 - f1_metrics: 0.8943 - val_loss: 1.7991 - val_accuracy: 0.0026 - val_precision: 0.6196 - val_recall: 0.5522 - val_f1_metrics: 0.5718\n",
            "Epoch 15/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3109 - accuracy: 0.0062 - precision: 0.9079 - recall: 0.8763 - f1_metrics: 0.8917 - val_loss: 1.7802 - val_accuracy: 0.0030 - val_precision: 0.6220 - val_recall: 0.5548 - val_f1_metrics: 0.5736\n",
            "Epoch 16/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2852 - accuracy: 0.0070 - precision: 0.9146 - recall: 0.8843 - f1_metrics: 0.8993 - val_loss: 1.8454 - val_accuracy: 0.0037 - val_precision: 0.6227 - val_recall: 0.5550 - val_f1_metrics: 0.5740\n",
            "Epoch 17/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2920 - accuracy: 0.0063 - precision: 0.9143 - recall: 0.8845 - f1_metrics: 0.8990 - val_loss: 1.7850 - val_accuracy: 0.0033 - val_precision: 0.6203 - val_recall: 0.5508 - val_f1_metrics: 0.5714\n",
            "Epoch 18/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2889 - accuracy: 0.0067 - precision: 0.9140 - recall: 0.8854 - f1_metrics: 0.8994 - val_loss: 1.7959 - val_accuracy: 0.0030 - val_precision: 0.6254 - val_recall: 0.5525 - val_f1_metrics: 0.5743\n",
            "Epoch 19/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.3012 - accuracy: 0.0063 - precision: 0.9124 - recall: 0.8817 - f1_metrics: 0.8969 - val_loss: 1.7390 - val_accuracy: 0.0023 - val_precision: 0.6287 - val_recall: 0.5559 - val_f1_metrics: 0.5772\n",
            "Epoch 20/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2925 - accuracy: 0.0061 - precision: 0.9124 - recall: 0.8835 - f1_metrics: 0.8976 - val_loss: 1.8145 - val_accuracy: 0.0028 - val_precision: 0.6169 - val_recall: 0.5456 - val_f1_metrics: 0.5663\n",
            "Epoch 21/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2884 - accuracy: 0.0070 - precision: 0.9144 - recall: 0.8861 - f1_metrics: 0.9000 - val_loss: 1.8647 - val_accuracy: 0.0029 - val_precision: 0.6242 - val_recall: 0.5600 - val_f1_metrics: 0.5780\n",
            "Epoch 22/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2888 - accuracy: 0.0082 - precision: 0.9126 - recall: 0.8845 - f1_metrics: 0.8980 - val_loss: 1.7520 - val_accuracy: 0.0029 - val_precision: 0.6201 - val_recall: 0.5559 - val_f1_metrics: 0.5731\n",
            "Epoch 23/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2797 - accuracy: 0.0068 - precision: 0.9170 - recall: 0.8890 - f1_metrics: 0.9025 - val_loss: 1.8401 - val_accuracy: 0.0039 - val_precision: 0.6205 - val_recall: 0.5522 - val_f1_metrics: 0.5717\n",
            "Epoch 24/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2823 - accuracy: 0.0072 - precision: 0.9174 - recall: 0.8891 - f1_metrics: 0.9029 - val_loss: 1.8399 - val_accuracy: 0.0034 - val_precision: 0.6201 - val_recall: 0.5511 - val_f1_metrics: 0.5776\n",
            "Epoch 25/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2892 - accuracy: 0.0072 - precision: 0.9161 - recall: 0.8863 - f1_metrics: 0.9008 - val_loss: 1.8320 - val_accuracy: 0.0035 - val_precision: 0.6244 - val_recall: 0.5581 - val_f1_metrics: 0.5766\n",
            "Epoch 26/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2845 - accuracy: 0.0065 - precision: 0.9156 - recall: 0.8877 - f1_metrics: 0.9013 - val_loss: 1.8042 - val_accuracy: 0.0027 - val_precision: 0.6240 - val_recall: 0.5589 - val_f1_metrics: 0.5783\n",
            "Epoch 27/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2730 - accuracy: 0.0074 - precision: 0.9168 - recall: 0.8910 - f1_metrics: 0.9035 - val_loss: 1.8435 - val_accuracy: 0.0043 - val_precision: 0.6238 - val_recall: 0.5581 - val_f1_metrics: 0.5777\n",
            "Epoch 28/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2715 - accuracy: 0.0077 - precision: 0.9184 - recall: 0.8922 - f1_metrics: 0.9052 - val_loss: 1.8864 - val_accuracy: 0.0023 - val_precision: 0.6166 - val_recall: 0.5520 - val_f1_metrics: 0.5828\n",
            "Epoch 29/100\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.2699 - accuracy: 0.0080 - precision: 0.9212 - recall: 0.8954 - f1_metrics: 0.9081 - val_loss: 1.8673 - val_accuracy: 0.0033 - val_precision: 0.6161 - val_recall: 0.5553 - val_f1_metrics: 0.5845\n",
            "Epoch 30/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2677 - accuracy: 0.0075 - precision: 0.9190 - recall: 0.8931 - f1_metrics: 0.9060 - val_loss: 1.8474 - val_accuracy: 0.0029 - val_precision: 0.6199 - val_recall: 0.5567 - val_f1_metrics: 0.5870\n",
            "Epoch 31/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2737 - accuracy: 0.0077 - precision: 0.9174 - recall: 0.8915 - f1_metrics: 0.9041 - val_loss: 1.8137 - val_accuracy: 0.0023 - val_precision: 0.6217 - val_recall: 0.5578 - val_f1_metrics: 0.5757\n",
            "Epoch 32/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2637 - accuracy: 0.0073 - precision: 0.9230 - recall: 0.8971 - f1_metrics: 0.9098 - val_loss: 1.8316 - val_accuracy: 0.0028 - val_precision: 0.6268 - val_recall: 0.5639 - val_f1_metrics: 0.5872\n",
            "Epoch 33/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2671 - accuracy: 0.0076 - precision: 0.9195 - recall: 0.8955 - f1_metrics: 0.9072 - val_loss: 1.8640 - val_accuracy: 0.0032 - val_precision: 0.6270 - val_recall: 0.5612 - val_f1_metrics: 0.5792\n",
            "Epoch 34/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2724 - accuracy: 0.0079 - precision: 0.9198 - recall: 0.8942 - f1_metrics: 0.9069 - val_loss: 1.8676 - val_accuracy: 0.0026 - val_precision: 0.6142 - val_recall: 0.5545 - val_f1_metrics: 0.5716\n",
            "Epoch 35/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2684 - accuracy: 0.0073 - precision: 0.9192 - recall: 0.8933 - f1_metrics: 0.9059 - val_loss: 1.8587 - val_accuracy: 0.0024 - val_precision: 0.6218 - val_recall: 0.5561 - val_f1_metrics: 0.5809\n",
            "Epoch 36/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2628 - accuracy: 0.0077 - precision: 0.9203 - recall: 0.8959 - f1_metrics: 0.9079 - val_loss: 1.9711 - val_accuracy: 0.0031 - val_precision: 0.6162 - val_recall: 0.5548 - val_f1_metrics: 0.5790\n",
            "Epoch 37/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2600 - accuracy: 0.0077 - precision: 0.9230 - recall: 0.8970 - f1_metrics: 0.9096 - val_loss: 2.0081 - val_accuracy: 0.0029 - val_precision: 0.6146 - val_recall: 0.5589 - val_f1_metrics: 0.5806\n",
            "Epoch 38/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2567 - accuracy: 0.0086 - precision: 0.9215 - recall: 0.8985 - f1_metrics: 0.9098 - val_loss: 1.8458 - val_accuracy: 0.0029 - val_precision: 0.6197 - val_recall: 0.5617 - val_f1_metrics: 0.5845\n",
            "Epoch 39/100\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.2587 - accuracy: 0.0085 - precision: 0.9211 - recall: 0.8984 - f1_metrics: 0.9092 - val_loss: 1.8806 - val_accuracy: 0.0035 - val_precision: 0.6180 - val_recall: 0.5589 - val_f1_metrics: 0.5873\n",
            "Epoch 40/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2611 - accuracy: 0.0081 - precision: 0.9220 - recall: 0.8983 - f1_metrics: 0.9100 - val_loss: 1.9128 - val_accuracy: 0.0041 - val_precision: 0.6146 - val_recall: 0.5589 - val_f1_metrics: 0.5858\n",
            "Epoch 41/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2663 - accuracy: 0.0086 - precision: 0.9209 - recall: 0.8962 - f1_metrics: 0.9086 - val_loss: 1.8533 - val_accuracy: 0.0036 - val_precision: 0.6227 - val_recall: 0.5584 - val_f1_metrics: 0.5826\n",
            "Epoch 42/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2496 - accuracy: 0.0087 - precision: 0.9245 - recall: 0.9021 - f1_metrics: 0.9131 - val_loss: 1.9087 - val_accuracy: 0.0030 - val_precision: 0.6213 - val_recall: 0.5651 - val_f1_metrics: 0.5869\n",
            "Epoch 43/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2524 - accuracy: 0.0087 - precision: 0.9258 - recall: 0.9023 - f1_metrics: 0.9140 - val_loss: 1.9111 - val_accuracy: 0.0029 - val_precision: 0.6159 - val_recall: 0.5628 - val_f1_metrics: 0.5821\n",
            "Epoch 44/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2432 - accuracy: 0.0095 - precision: 0.9281 - recall: 0.9071 - f1_metrics: 0.9177 - val_loss: 1.9027 - val_accuracy: 0.0034 - val_precision: 0.6203 - val_recall: 0.5612 - val_f1_metrics: 0.5764\n",
            "Epoch 45/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2557 - accuracy: 0.0089 - precision: 0.9242 - recall: 0.9008 - f1_metrics: 0.9122 - val_loss: 1.8579 - val_accuracy: 0.0038 - val_precision: 0.6181 - val_recall: 0.5550 - val_f1_metrics: 0.5803\n",
            "Epoch 46/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2492 - accuracy: 0.0090 - precision: 0.9251 - recall: 0.9019 - f1_metrics: 0.9131 - val_loss: 1.9357 - val_accuracy: 0.0044 - val_precision: 0.6179 - val_recall: 0.5578 - val_f1_metrics: 0.5802\n",
            "Epoch 47/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2484 - accuracy: 0.0106 - precision: 0.9256 - recall: 0.9033 - f1_metrics: 0.9140 - val_loss: 1.9627 - val_accuracy: 0.0041 - val_precision: 0.6120 - val_recall: 0.5520 - val_f1_metrics: 0.5760\n",
            "Epoch 48/100\n",
            "225/225 [==============================] - 8s 36ms/step - loss: 0.2435 - accuracy: 0.0096 - precision: 0.9269 - recall: 0.9057 - f1_metrics: 0.9161 - val_loss: 1.8897 - val_accuracy: 0.0037 - val_precision: 0.6156 - val_recall: 0.5570 - val_f1_metrics: 0.5720\n",
            "Epoch 49/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2474 - accuracy: 0.0088 - precision: 0.9250 - recall: 0.9037 - f1_metrics: 0.9142 - val_loss: 1.8635 - val_accuracy: 0.0032 - val_precision: 0.6156 - val_recall: 0.5525 - val_f1_metrics: 0.5778\n",
            "Epoch 50/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2365 - accuracy: 0.0092 - precision: 0.9290 - recall: 0.9092 - f1_metrics: 0.9190 - val_loss: 1.9412 - val_accuracy: 0.0044 - val_precision: 0.6156 - val_recall: 0.5520 - val_f1_metrics: 0.5829\n",
            "Epoch 51/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2391 - accuracy: 0.0102 - precision: 0.9260 - recall: 0.9062 - f1_metrics: 0.9160 - val_loss: 1.9275 - val_accuracy: 0.0043 - val_precision: 0.6108 - val_recall: 0.5559 - val_f1_metrics: 0.5762\n",
            "Epoch 52/100\n",
            "225/225 [==============================] - 8s 34ms/step - loss: 0.2514 - accuracy: 0.0088 - precision: 0.9246 - recall: 0.9027 - f1_metrics: 0.9138 - val_loss: 1.9083 - val_accuracy: 0.0038 - val_precision: 0.6143 - val_recall: 0.5539 - val_f1_metrics: 0.5766\n",
            "Epoch 53/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2340 - accuracy: 0.0101 - precision: 0.9286 - recall: 0.9102 - f1_metrics: 0.9189 - val_loss: 2.0193 - val_accuracy: 0.0036 - val_precision: 0.6097 - val_recall: 0.5584 - val_f1_metrics: 0.5769\n",
            "Epoch 54/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2383 - accuracy: 0.0101 - precision: 0.9299 - recall: 0.9096 - f1_metrics: 0.9195 - val_loss: 1.9522 - val_accuracy: 0.0033 - val_precision: 0.6105 - val_recall: 0.5556 - val_f1_metrics: 0.5759\n",
            "Epoch 55/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2420 - accuracy: 0.0093 - precision: 0.9271 - recall: 0.9062 - f1_metrics: 0.9165 - val_loss: 1.8170 - val_accuracy: 0.0026 - val_precision: 0.6213 - val_recall: 0.5603 - val_f1_metrics: 0.5829\n",
            "Epoch 56/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2298 - accuracy: 0.0095 - precision: 0.9312 - recall: 0.9106 - f1_metrics: 0.9208 - val_loss: 1.9436 - val_accuracy: 0.0029 - val_precision: 0.6154 - val_recall: 0.5617 - val_f1_metrics: 0.5810\n",
            "Epoch 57/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2417 - accuracy: 0.0100 - precision: 0.9286 - recall: 0.9078 - f1_metrics: 0.9180 - val_loss: 1.8858 - val_accuracy: 0.0027 - val_precision: 0.6188 - val_recall: 0.5550 - val_f1_metrics: 0.5731\n",
            "Epoch 58/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2460 - accuracy: 0.0095 - precision: 0.9271 - recall: 0.9067 - f1_metrics: 0.9167 - val_loss: 1.9309 - val_accuracy: 0.0038 - val_precision: 0.6135 - val_recall: 0.5573 - val_f1_metrics: 0.5778\n",
            "Epoch 59/100\n",
            "225/225 [==============================] - 8s 33ms/step - loss: 0.2423 - accuracy: 0.0097 - precision: 0.9279 - recall: 0.9063 - f1_metrics: 0.9170 - val_loss: 1.9407 - val_accuracy: 0.0042 - val_precision: 0.6092 - val_recall: 0.5556 - val_f1_metrics: 0.5685\n",
            "Epoch 60/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2356 - accuracy: 0.0103 - precision: 0.9298 - recall: 0.9092 - f1_metrics: 0.9192 - val_loss: 1.9971 - val_accuracy: 0.0037 - val_precision: 0.6056 - val_recall: 0.5503 - val_f1_metrics: 0.5647\n",
            "Epoch 61/100\n",
            "225/225 [==============================] - 8s 34ms/step - loss: 0.2320 - accuracy: 0.0105 - precision: 0.9296 - recall: 0.9106 - f1_metrics: 0.9200 - val_loss: 2.0426 - val_accuracy: 0.0036 - val_precision: 0.6076 - val_recall: 0.5514 - val_f1_metrics: 0.5656\n",
            "Epoch 62/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2320 - accuracy: 0.0108 - precision: 0.9296 - recall: 0.9114 - f1_metrics: 0.9204 - val_loss: 1.9416 - val_accuracy: 0.0045 - val_precision: 0.6137 - val_recall: 0.5542 - val_f1_metrics: 0.5764\n",
            "Epoch 63/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2449 - accuracy: 0.0099 - precision: 0.9277 - recall: 0.9062 - f1_metrics: 0.9167 - val_loss: 1.9747 - val_accuracy: 0.0039 - val_precision: 0.6069 - val_recall: 0.5458 - val_f1_metrics: 0.5689\n",
            "Epoch 64/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2264 - accuracy: 0.0117 - precision: 0.9328 - recall: 0.9138 - f1_metrics: 0.9233 - val_loss: 1.9914 - val_accuracy: 0.0049 - val_precision: 0.6137 - val_recall: 0.5573 - val_f1_metrics: 0.5721\n",
            "Epoch 65/100\n",
            "225/225 [==============================] - 8s 33ms/step - loss: 0.2352 - accuracy: 0.0106 - precision: 0.9305 - recall: 0.9117 - f1_metrics: 0.9210 - val_loss: 2.0183 - val_accuracy: 0.0040 - val_precision: 0.6069 - val_recall: 0.5511 - val_f1_metrics: 0.5719\n",
            "Epoch 66/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2281 - accuracy: 0.0106 - precision: 0.9321 - recall: 0.9134 - f1_metrics: 0.9226 - val_loss: 2.0430 - val_accuracy: 0.0038 - val_precision: 0.6137 - val_recall: 0.5617 - val_f1_metrics: 0.5803\n",
            "Epoch 67/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2203 - accuracy: 0.0108 - precision: 0.9338 - recall: 0.9163 - f1_metrics: 0.9248 - val_loss: 2.0455 - val_accuracy: 0.0051 - val_precision: 0.6207 - val_recall: 0.5645 - val_f1_metrics: 0.5784\n",
            "Epoch 68/100\n",
            "225/225 [==============================] - 8s 33ms/step - loss: 0.2292 - accuracy: 0.0122 - precision: 0.9319 - recall: 0.9147 - f1_metrics: 0.9232 - val_loss: 2.0195 - val_accuracy: 0.0049 - val_precision: 0.6103 - val_recall: 0.5528 - val_f1_metrics: 0.5683\n",
            "Epoch 69/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2293 - accuracy: 0.0107 - precision: 0.9320 - recall: 0.9135 - f1_metrics: 0.9224 - val_loss: 1.9775 - val_accuracy: 0.0034 - val_precision: 0.6142 - val_recall: 0.5581 - val_f1_metrics: 0.5721\n",
            "Epoch 70/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2219 - accuracy: 0.0111 - precision: 0.9343 - recall: 0.9160 - f1_metrics: 0.9251 - val_loss: 2.0705 - val_accuracy: 0.0051 - val_precision: 0.6153 - val_recall: 0.5651 - val_f1_metrics: 0.5828\n",
            "Epoch 71/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2303 - accuracy: 0.0117 - precision: 0.9307 - recall: 0.9125 - f1_metrics: 0.9215 - val_loss: 1.9964 - val_accuracy: 0.0041 - val_precision: 0.6106 - val_recall: 0.5478 - val_f1_metrics: 0.5715\n",
            "Epoch 72/100\n",
            "225/225 [==============================] - 8s 33ms/step - loss: 0.2270 - accuracy: 0.0112 - precision: 0.9304 - recall: 0.9123 - f1_metrics: 0.9213 - val_loss: 1.9861 - val_accuracy: 0.0040 - val_precision: 0.6176 - val_recall: 0.5670 - val_f1_metrics: 0.5849\n",
            "Epoch 73/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2287 - accuracy: 0.0112 - precision: 0.9334 - recall: 0.9152 - f1_metrics: 0.9241 - val_loss: 2.0040 - val_accuracy: 0.0046 - val_precision: 0.6028 - val_recall: 0.5483 - val_f1_metrics: 0.5620\n",
            "Epoch 74/100\n",
            "225/225 [==============================] - 8s 33ms/step - loss: 0.2227 - accuracy: 0.0118 - precision: 0.9338 - recall: 0.9163 - f1_metrics: 0.9252 - val_loss: 2.0689 - val_accuracy: 0.0059 - val_precision: 0.6097 - val_recall: 0.5606 - val_f1_metrics: 0.5793\n",
            "Epoch 75/100\n",
            "225/225 [==============================] - 8s 34ms/step - loss: 0.2209 - accuracy: 0.0117 - precision: 0.9328 - recall: 0.9155 - f1_metrics: 0.9240 - val_loss: 2.0057 - val_accuracy: 0.0056 - val_precision: 0.6139 - val_recall: 0.5550 - val_f1_metrics: 0.5769\n",
            "Epoch 76/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2196 - accuracy: 0.0113 - precision: 0.9347 - recall: 0.9159 - f1_metrics: 0.9253 - val_loss: 1.9511 - val_accuracy: 0.0054 - val_precision: 0.6042 - val_recall: 0.5422 - val_f1_metrics: 0.5672\n",
            "Epoch 77/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2120 - accuracy: 0.0112 - precision: 0.9375 - recall: 0.9197 - f1_metrics: 0.9286 - val_loss: 1.9879 - val_accuracy: 0.0048 - val_precision: 0.6124 - val_recall: 0.5548 - val_f1_metrics: 0.5777\n",
            "Epoch 78/100\n",
            "225/225 [==============================] - 8s 33ms/step - loss: 0.2107 - accuracy: 0.0119 - precision: 0.9379 - recall: 0.9201 - f1_metrics: 0.9290 - val_loss: 2.0569 - val_accuracy: 0.0047 - val_precision: 0.6086 - val_recall: 0.5559 - val_f1_metrics: 0.5752\n",
            "Epoch 79/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2138 - accuracy: 0.0119 - precision: 0.9343 - recall: 0.9178 - f1_metrics: 0.9261 - val_loss: 1.9950 - val_accuracy: 0.0048 - val_precision: 0.6143 - val_recall: 0.5587 - val_f1_metrics: 0.5791\n",
            "Epoch 80/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2102 - accuracy: 0.0129 - precision: 0.9364 - recall: 0.9202 - f1_metrics: 0.9282 - val_loss: 2.0486 - val_accuracy: 0.0056 - val_precision: 0.6147 - val_recall: 0.5637 - val_f1_metrics: 0.5833\n",
            "Epoch 81/100\n",
            "225/225 [==============================] - 8s 33ms/step - loss: 0.2135 - accuracy: 0.0127 - precision: 0.9365 - recall: 0.9193 - f1_metrics: 0.9278 - val_loss: 2.0627 - val_accuracy: 0.0043 - val_precision: 0.6036 - val_recall: 0.5495 - val_f1_metrics: 0.5635\n",
            "Epoch 82/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2107 - accuracy: 0.0121 - precision: 0.9370 - recall: 0.9217 - f1_metrics: 0.9290 - val_loss: 2.0345 - val_accuracy: 0.0047 - val_precision: 0.6122 - val_recall: 0.5578 - val_f1_metrics: 0.5718\n",
            "Epoch 83/100\n",
            "225/225 [==============================] - 8s 33ms/step - loss: 0.2270 - accuracy: 0.0126 - precision: 0.9311 - recall: 0.9148 - f1_metrics: 0.9227 - val_loss: 2.0111 - val_accuracy: 0.0041 - val_precision: 0.6132 - val_recall: 0.5517 - val_f1_metrics: 0.5764\n",
            "Epoch 84/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2138 - accuracy: 0.0128 - precision: 0.9353 - recall: 0.9178 - f1_metrics: 0.9266 - val_loss: 2.0143 - val_accuracy: 0.0052 - val_precision: 0.6079 - val_recall: 0.5517 - val_f1_metrics: 0.5658\n",
            "Epoch 85/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2128 - accuracy: 0.0132 - precision: 0.9350 - recall: 0.9166 - f1_metrics: 0.9256 - val_loss: 2.1359 - val_accuracy: 0.0056 - val_precision: 0.6004 - val_recall: 0.5481 - val_f1_metrics: 0.5687\n",
            "Epoch 86/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2161 - accuracy: 0.0131 - precision: 0.9370 - recall: 0.9199 - f1_metrics: 0.9284 - val_loss: 2.0082 - val_accuracy: 0.0045 - val_precision: 0.6127 - val_recall: 0.5559 - val_f1_metrics: 0.5702\n",
            "Epoch 87/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2188 - accuracy: 0.0130 - precision: 0.9361 - recall: 0.9198 - f1_metrics: 0.9278 - val_loss: 2.0991 - val_accuracy: 0.0074 - val_precision: 0.6026 - val_recall: 0.5517 - val_f1_metrics: 0.5716\n",
            "Epoch 88/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2152 - accuracy: 0.0130 - precision: 0.9347 - recall: 0.9192 - f1_metrics: 0.9269 - val_loss: 2.0344 - val_accuracy: 0.0055 - val_precision: 0.6149 - val_recall: 0.5606 - val_f1_metrics: 0.5746\n",
            "Epoch 89/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2002 - accuracy: 0.0134 - precision: 0.9395 - recall: 0.9254 - f1_metrics: 0.9322 - val_loss: 2.0426 - val_accuracy: 0.0042 - val_precision: 0.6036 - val_recall: 0.5469 - val_f1_metrics: 0.5696\n",
            "Epoch 90/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2179 - accuracy: 0.0123 - precision: 0.9358 - recall: 0.9184 - f1_metrics: 0.9269 - val_loss: 2.0868 - val_accuracy: 0.0043 - val_precision: 0.6065 - val_recall: 0.5548 - val_f1_metrics: 0.5675\n",
            "Epoch 91/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2093 - accuracy: 0.0130 - precision: 0.9365 - recall: 0.9209 - f1_metrics: 0.9288 - val_loss: 2.0730 - val_accuracy: 0.0067 - val_precision: 0.6131 - val_recall: 0.5559 - val_f1_metrics: 0.5783\n",
            "Epoch 92/100\n",
            "225/225 [==============================] - 8s 33ms/step - loss: 0.2182 - accuracy: 0.0145 - precision: 0.9355 - recall: 0.9197 - f1_metrics: 0.9276 - val_loss: 2.0166 - val_accuracy: 0.0043 - val_precision: 0.6124 - val_recall: 0.5511 - val_f1_metrics: 0.5683\n",
            "Epoch 93/100\n",
            "225/225 [==============================] - 8s 34ms/step - loss: 0.2083 - accuracy: 0.0140 - precision: 0.9380 - recall: 0.9225 - f1_metrics: 0.9302 - val_loss: 2.0303 - val_accuracy: 0.0051 - val_precision: 0.6165 - val_recall: 0.5634 - val_f1_metrics: 0.5890\n",
            "Epoch 94/100\n",
            "225/225 [==============================] - 8s 34ms/step - loss: 0.2059 - accuracy: 0.0142 - precision: 0.9387 - recall: 0.9232 - f1_metrics: 0.9310 - val_loss: 2.0927 - val_accuracy: 0.0057 - val_precision: 0.6105 - val_recall: 0.5559 - val_f1_metrics: 0.5711\n",
            "Epoch 95/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2154 - accuracy: 0.0147 - precision: 0.9342 - recall: 0.9179 - f1_metrics: 0.9258 - val_loss: 2.0331 - val_accuracy: 0.0049 - val_precision: 0.6132 - val_recall: 0.5575 - val_f1_metrics: 0.5793\n",
            "Epoch 96/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2063 - accuracy: 0.0144 - precision: 0.9370 - recall: 0.9227 - f1_metrics: 0.9299 - val_loss: 2.1049 - val_accuracy: 0.0054 - val_precision: 0.6072 - val_recall: 0.5564 - val_f1_metrics: 0.5813\n",
            "Epoch 97/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2087 - accuracy: 0.0145 - precision: 0.9369 - recall: 0.9203 - f1_metrics: 0.9285 - val_loss: 2.1010 - val_accuracy: 0.0062 - val_precision: 0.6082 - val_recall: 0.5570 - val_f1_metrics: 0.5767\n",
            "Epoch 98/100\n",
            "225/225 [==============================] - 7s 33ms/step - loss: 0.2179 - accuracy: 0.0136 - precision: 0.9368 - recall: 0.9203 - f1_metrics: 0.9283 - val_loss: 2.0783 - val_accuracy: 0.0054 - val_precision: 0.6088 - val_recall: 0.5612 - val_f1_metrics: 0.5794\n",
            "Epoch 99/100\n",
            "225/225 [==============================] - 8s 33ms/step - loss: 0.2005 - accuracy: 0.0147 - precision: 0.9404 - recall: 0.9240 - f1_metrics: 0.9321 - val_loss: 2.0298 - val_accuracy: 0.0047 - val_precision: 0.6084 - val_recall: 0.5545 - val_f1_metrics: 0.5754\n",
            "Epoch 100/100\n",
            "225/225 [==============================] - 8s 33ms/step - loss: 0.2132 - accuracy: 0.0136 - precision: 0.9363 - recall: 0.9204 - f1_metrics: 0.9281 - val_loss: 2.0842 - val_accuracy: 0.0061 - val_precision: 0.6099 - val_recall: 0.5559 - val_f1_metrics: 0.5756\n",
            "VGGD16Custom | batch_size: 256 | epochs: 30\n",
            "Epoch 1/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1708 - accuracy: 0.0158 - precision: 0.9476 - recall: 0.9355 - f1_metrics: 0.9419 - val_loss: 2.1556 - val_accuracy: 0.0064 - val_precision: 0.6047 - val_recall: 0.5553 - val_f1_metrics: 0.5672\n",
            "Epoch 2/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1410 - accuracy: 0.0182 - precision: 0.9569 - recall: 0.9472 - f1_metrics: 0.9524 - val_loss: 2.2065 - val_accuracy: 0.0082 - val_precision: 0.6141 - val_recall: 0.5734 - val_f1_metrics: 0.5834\n",
            "Epoch 3/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1317 - accuracy: 0.0205 - precision: 0.9603 - recall: 0.9524 - f1_metrics: 0.9565 - val_loss: 2.2401 - val_accuracy: 0.0084 - val_precision: 0.6114 - val_recall: 0.5698 - val_f1_metrics: 0.5803\n",
            "Epoch 4/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1372 - accuracy: 0.0208 - precision: 0.9607 - recall: 0.9518 - f1_metrics: 0.9561 - val_loss: 2.1721 - val_accuracy: 0.0083 - val_precision: 0.6126 - val_recall: 0.5653 - val_f1_metrics: 0.5641\n",
            "Epoch 5/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1297 - accuracy: 0.0223 - precision: 0.9608 - recall: 0.9522 - f1_metrics: 0.9566 - val_loss: 2.2705 - val_accuracy: 0.0086 - val_precision: 0.6094 - val_recall: 0.5642 - val_f1_metrics: 0.5767\n",
            "Epoch 6/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1250 - accuracy: 0.0229 - precision: 0.9618 - recall: 0.9533 - f1_metrics: 0.9572 - val_loss: 2.2752 - val_accuracy: 0.0097 - val_precision: 0.6186 - val_recall: 0.5717 - val_f1_metrics: 0.5946\n",
            "Epoch 7/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1294 - accuracy: 0.0231 - precision: 0.9603 - recall: 0.9514 - f1_metrics: 0.9561 - val_loss: 2.2628 - val_accuracy: 0.0078 - val_precision: 0.6159 - val_recall: 0.5751 - val_f1_metrics: 0.5820\n",
            "Epoch 8/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1207 - accuracy: 0.0224 - precision: 0.9633 - recall: 0.9558 - f1_metrics: 0.9597 - val_loss: 2.2438 - val_accuracy: 0.0072 - val_precision: 0.6079 - val_recall: 0.5698 - val_f1_metrics: 0.5890\n",
            "Epoch 9/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1223 - accuracy: 0.0221 - precision: 0.9618 - recall: 0.9542 - f1_metrics: 0.9577 - val_loss: 2.3606 - val_accuracy: 0.0097 - val_precision: 0.6057 - val_recall: 0.5701 - val_f1_metrics: 0.5751\n",
            "Epoch 10/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1201 - accuracy: 0.0250 - precision: 0.9636 - recall: 0.9560 - f1_metrics: 0.9601 - val_loss: 2.3400 - val_accuracy: 0.0117 - val_precision: 0.6130 - val_recall: 0.5743 - val_f1_metrics: 0.5687\n",
            "Epoch 11/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1326 - accuracy: 0.0248 - precision: 0.9595 - recall: 0.9514 - f1_metrics: 0.9555 - val_loss: 2.2894 - val_accuracy: 0.0087 - val_precision: 0.6038 - val_recall: 0.5651 - val_f1_metrics: 0.5718\n",
            "Epoch 12/30\n",
            "113/113 [==============================] - 7s 61ms/step - loss: 0.1322 - accuracy: 0.0226 - precision: 0.9596 - recall: 0.9521 - f1_metrics: 0.9558 - val_loss: 2.2701 - val_accuracy: 0.0090 - val_precision: 0.6014 - val_recall: 0.5637 - val_f1_metrics: 0.5701\n",
            "Epoch 13/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1265 - accuracy: 0.0216 - precision: 0.9618 - recall: 0.9539 - f1_metrics: 0.9581 - val_loss: 2.2875 - val_accuracy: 0.0082 - val_precision: 0.6023 - val_recall: 0.5637 - val_f1_metrics: 0.5834\n",
            "Epoch 14/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1199 - accuracy: 0.0237 - precision: 0.9623 - recall: 0.9558 - f1_metrics: 0.9583 - val_loss: 2.4541 - val_accuracy: 0.0116 - val_precision: 0.6068 - val_recall: 0.5731 - val_f1_metrics: 0.5654\n",
            "Epoch 15/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1284 - accuracy: 0.0250 - precision: 0.9611 - recall: 0.9532 - f1_metrics: 0.9568 - val_loss: 2.3077 - val_accuracy: 0.0088 - val_precision: 0.6013 - val_recall: 0.5584 - val_f1_metrics: 0.5702\n",
            "Epoch 16/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1269 - accuracy: 0.0231 - precision: 0.9616 - recall: 0.9540 - f1_metrics: 0.9575 - val_loss: 2.3908 - val_accuracy: 0.0099 - val_precision: 0.6021 - val_recall: 0.5626 - val_f1_metrics: 0.5727\n",
            "Epoch 17/30\n",
            "113/113 [==============================] - 7s 61ms/step - loss: 0.1392 - accuracy: 0.0232 - precision: 0.9576 - recall: 0.9491 - f1_metrics: 0.9537 - val_loss: 2.2839 - val_accuracy: 0.0070 - val_precision: 0.6007 - val_recall: 0.5587 - val_f1_metrics: 0.5700\n",
            "Epoch 18/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1326 - accuracy: 0.0214 - precision: 0.9590 - recall: 0.9500 - f1_metrics: 0.9540 - val_loss: 2.2931 - val_accuracy: 0.0086 - val_precision: 0.6016 - val_recall: 0.5595 - val_f1_metrics: 0.5550\n",
            "Epoch 19/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1424 - accuracy: 0.0218 - precision: 0.9561 - recall: 0.9470 - f1_metrics: 0.9519 - val_loss: 2.3042 - val_accuracy: 0.0078 - val_precision: 0.6062 - val_recall: 0.5648 - val_f1_metrics: 0.5610\n",
            "Epoch 20/30\n",
            "113/113 [==============================] - 7s 61ms/step - loss: 0.1346 - accuracy: 0.0240 - precision: 0.9587 - recall: 0.9501 - f1_metrics: 0.9544 - val_loss: 2.3329 - val_accuracy: 0.0091 - val_precision: 0.6023 - val_recall: 0.5612 - val_f1_metrics: 0.5575\n",
            "Epoch 21/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1377 - accuracy: 0.0230 - precision: 0.9584 - recall: 0.9505 - f1_metrics: 0.9544 - val_loss: 2.2658 - val_accuracy: 0.0084 - val_precision: 0.6084 - val_recall: 0.5631 - val_f1_metrics: 0.5859\n",
            "Epoch 22/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1444 - accuracy: 0.0213 - precision: 0.9562 - recall: 0.9463 - f1_metrics: 0.9516 - val_loss: 2.2068 - val_accuracy: 0.0092 - val_precision: 0.6080 - val_recall: 0.5656 - val_f1_metrics: 0.5738\n",
            "Epoch 23/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1235 - accuracy: 0.0247 - precision: 0.9612 - recall: 0.9535 - f1_metrics: 0.9576 - val_loss: 2.3775 - val_accuracy: 0.0092 - val_precision: 0.6022 - val_recall: 0.5639 - val_f1_metrics: 0.5836\n",
            "Epoch 24/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1276 - accuracy: 0.0250 - precision: 0.9611 - recall: 0.9534 - f1_metrics: 0.9575 - val_loss: 2.3181 - val_accuracy: 0.0084 - val_precision: 0.5996 - val_recall: 0.5575 - val_f1_metrics: 0.5793\n",
            "Epoch 25/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1313 - accuracy: 0.0224 - precision: 0.9613 - recall: 0.9535 - f1_metrics: 0.9575 - val_loss: 2.2304 - val_accuracy: 0.0087 - val_precision: 0.6130 - val_recall: 0.5662 - val_f1_metrics: 0.5894\n",
            "Epoch 26/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1312 - accuracy: 0.0236 - precision: 0.9598 - recall: 0.9513 - f1_metrics: 0.9558 - val_loss: 2.3403 - val_accuracy: 0.0088 - val_precision: 0.6064 - val_recall: 0.5687 - val_f1_metrics: 0.5629\n",
            "Epoch 27/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1258 - accuracy: 0.0244 - precision: 0.9608 - recall: 0.9533 - f1_metrics: 0.9564 - val_loss: 2.3078 - val_accuracy: 0.0091 - val_precision: 0.6059 - val_recall: 0.5676 - val_f1_metrics: 0.5623\n",
            "Epoch 28/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1353 - accuracy: 0.0228 - precision: 0.9599 - recall: 0.9506 - f1_metrics: 0.9554 - val_loss: 2.2659 - val_accuracy: 0.0082 - val_precision: 0.6047 - val_recall: 0.5614 - val_f1_metrics: 0.5733\n",
            "Epoch 29/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1302 - accuracy: 0.0233 - precision: 0.9618 - recall: 0.9532 - f1_metrics: 0.9570 - val_loss: 2.3073 - val_accuracy: 0.0112 - val_precision: 0.6045 - val_recall: 0.5595 - val_f1_metrics: 0.5575\n",
            "Epoch 30/30\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1449 - accuracy: 0.0226 - precision: 0.9568 - recall: 0.9481 - f1_metrics: 0.9522 - val_loss: 2.2603 - val_accuracy: 0.0077 - val_precision: 0.6039 - val_recall: 0.5662 - val_f1_metrics: 0.5607\n",
            "VGGD16Custom | batch_size: 256 | epochs: 50\n",
            "Epoch 1/50\n",
            "  2/113 [..............................] - ETA: 3s - loss: 0.1610 - accuracy: 0.0198 - precision: 0.9607 - recall: 0.9551 - f1_metrics: 0.9579WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0235s vs `on_train_batch_end` time: 0.0359s). Check your callbacks.\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1433 - accuracy: 0.0232 - precision: 0.9561 - recall: 0.9479 - f1_metrics: 0.9513 - val_loss: 2.3274 - val_accuracy: 0.0089 - val_precision: 0.6048 - val_recall: 0.5662 - val_f1_metrics: 0.5755\n",
            "Epoch 2/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1430 - accuracy: 0.0218 - precision: 0.9569 - recall: 0.9471 - f1_metrics: 0.9522 - val_loss: 2.2646 - val_accuracy: 0.0082 - val_precision: 0.6120 - val_recall: 0.5723 - val_f1_metrics: 0.5819\n",
            "Epoch 3/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1343 - accuracy: 0.0224 - precision: 0.9600 - recall: 0.9522 - f1_metrics: 0.9558 - val_loss: 2.2542 - val_accuracy: 0.0084 - val_precision: 0.6053 - val_recall: 0.5648 - val_f1_metrics: 0.5607\n",
            "Epoch 4/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1352 - accuracy: 0.0218 - precision: 0.9601 - recall: 0.9518 - f1_metrics: 0.9561 - val_loss: 2.2251 - val_accuracy: 0.0079 - val_precision: 0.6073 - val_recall: 0.5653 - val_f1_metrics: 0.5734\n",
            "Epoch 5/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1288 - accuracy: 0.0233 - precision: 0.9602 - recall: 0.9527 - f1_metrics: 0.9566 - val_loss: 2.2958 - val_accuracy: 0.0082 - val_precision: 0.6099 - val_recall: 0.5667 - val_f1_metrics: 0.5622\n",
            "Epoch 6/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1345 - accuracy: 0.0226 - precision: 0.9601 - recall: 0.9524 - f1_metrics: 0.9566 - val_loss: 2.2961 - val_accuracy: 0.0097 - val_precision: 0.6100 - val_recall: 0.5678 - val_f1_metrics: 0.5758\n",
            "Epoch 7/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1240 - accuracy: 0.0237 - precision: 0.9617 - recall: 0.9547 - f1_metrics: 0.9583 - val_loss: 2.3015 - val_accuracy: 0.0080 - val_precision: 0.6096 - val_recall: 0.5704 - val_f1_metrics: 0.5653\n",
            "Epoch 8/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1255 - accuracy: 0.0242 - precision: 0.9622 - recall: 0.9547 - f1_metrics: 0.9586 - val_loss: 2.3168 - val_accuracy: 0.0082 - val_precision: 0.6096 - val_recall: 0.5712 - val_f1_metrics: 0.5773\n",
            "Epoch 9/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1272 - accuracy: 0.0236 - precision: 0.9610 - recall: 0.9530 - f1_metrics: 0.9571 - val_loss: 2.3365 - val_accuracy: 0.0086 - val_precision: 0.6097 - val_recall: 0.5681 - val_f1_metrics: 0.5629\n",
            "Epoch 10/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1369 - accuracy: 0.0236 - precision: 0.9580 - recall: 0.9498 - f1_metrics: 0.9538 - val_loss: 2.4144 - val_accuracy: 0.0085 - val_precision: 0.6065 - val_recall: 0.5704 - val_f1_metrics: 0.5624\n",
            "Epoch 11/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1365 - accuracy: 0.0222 - precision: 0.9591 - recall: 0.9503 - f1_metrics: 0.9545 - val_loss: 2.2905 - val_accuracy: 0.0077 - val_precision: 0.6026 - val_recall: 0.5612 - val_f1_metrics: 0.5562\n",
            "Epoch 12/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1382 - accuracy: 0.0220 - precision: 0.9581 - recall: 0.9503 - f1_metrics: 0.9545 - val_loss: 2.2752 - val_accuracy: 0.0090 - val_precision: 0.6106 - val_recall: 0.5670 - val_f1_metrics: 0.5626\n",
            "Epoch 13/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1268 - accuracy: 0.0241 - precision: 0.9612 - recall: 0.9529 - f1_metrics: 0.9573 - val_loss: 2.3658 - val_accuracy: 0.0088 - val_precision: 0.6111 - val_recall: 0.5687 - val_f1_metrics: 0.5767\n",
            "Epoch 14/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1377 - accuracy: 0.0247 - precision: 0.9587 - recall: 0.9510 - f1_metrics: 0.9546 - val_loss: 2.3700 - val_accuracy: 0.0100 - val_precision: 0.6113 - val_recall: 0.5709 - val_f1_metrics: 0.5649\n",
            "Epoch 15/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1288 - accuracy: 0.0254 - precision: 0.9599 - recall: 0.9516 - f1_metrics: 0.9559 - val_loss: 2.4096 - val_accuracy: 0.0106 - val_precision: 0.6082 - val_recall: 0.5709 - val_f1_metrics: 0.5767\n",
            "Epoch 16/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1310 - accuracy: 0.0267 - precision: 0.9615 - recall: 0.9537 - f1_metrics: 0.9578 - val_loss: 2.3296 - val_accuracy: 0.0088 - val_precision: 0.6088 - val_recall: 0.5698 - val_f1_metrics: 0.5763\n",
            "Epoch 17/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1306 - accuracy: 0.0239 - precision: 0.9609 - recall: 0.9544 - f1_metrics: 0.9577 - val_loss: 2.3207 - val_accuracy: 0.0082 - val_precision: 0.6078 - val_recall: 0.5726 - val_f1_metrics: 0.5641\n",
            "Epoch 18/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1352 - accuracy: 0.0224 - precision: 0.9601 - recall: 0.9515 - f1_metrics: 0.9556 - val_loss: 2.2982 - val_accuracy: 0.0089 - val_precision: 0.6136 - val_recall: 0.5734 - val_f1_metrics: 0.5831\n",
            "Epoch 19/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1344 - accuracy: 0.0247 - precision: 0.9600 - recall: 0.9534 - f1_metrics: 0.9567 - val_loss: 2.3113 - val_accuracy: 0.0105 - val_precision: 0.6048 - val_recall: 0.5645 - val_f1_metrics: 0.5719\n",
            "Epoch 20/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1286 - accuracy: 0.0237 - precision: 0.9606 - recall: 0.9525 - f1_metrics: 0.9564 - val_loss: 2.3433 - val_accuracy: 0.0084 - val_precision: 0.6121 - val_recall: 0.5734 - val_f1_metrics: 0.5679\n",
            "Epoch 21/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1228 - accuracy: 0.0260 - precision: 0.9612 - recall: 0.9544 - f1_metrics: 0.9579 - val_loss: 2.3704 - val_accuracy: 0.0092 - val_precision: 0.6152 - val_recall: 0.5787 - val_f1_metrics: 0.5719\n",
            "Epoch 22/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1247 - accuracy: 0.0256 - precision: 0.9619 - recall: 0.9558 - f1_metrics: 0.9591 - val_loss: 2.3351 - val_accuracy: 0.0081 - val_precision: 0.6117 - val_recall: 0.5731 - val_f1_metrics: 0.5676\n",
            "Epoch 23/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1370 - accuracy: 0.0252 - precision: 0.9589 - recall: 0.9505 - f1_metrics: 0.9550 - val_loss: 2.3309 - val_accuracy: 0.0087 - val_precision: 0.6096 - val_recall: 0.5717 - val_f1_metrics: 0.5804\n",
            "Epoch 24/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1271 - accuracy: 0.0236 - precision: 0.9615 - recall: 0.9540 - f1_metrics: 0.9578 - val_loss: 2.2869 - val_accuracy: 0.0084 - val_precision: 0.6132 - val_recall: 0.5706 - val_f1_metrics: 0.5656\n",
            "Epoch 25/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1273 - accuracy: 0.0249 - precision: 0.9613 - recall: 0.9524 - f1_metrics: 0.9571 - val_loss: 2.3495 - val_accuracy: 0.0092 - val_precision: 0.6128 - val_recall: 0.5720 - val_f1_metrics: 0.5661\n",
            "Epoch 26/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1324 - accuracy: 0.0243 - precision: 0.9596 - recall: 0.9519 - f1_metrics: 0.9561 - val_loss: 2.2743 - val_accuracy: 0.0083 - val_precision: 0.6117 - val_recall: 0.5701 - val_f1_metrics: 0.5659\n",
            "Epoch 27/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1252 - accuracy: 0.0224 - precision: 0.9626 - recall: 0.9546 - f1_metrics: 0.9588 - val_loss: 2.2864 - val_accuracy: 0.0073 - val_precision: 0.6118 - val_recall: 0.5681 - val_f1_metrics: 0.5650\n",
            "Epoch 28/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1231 - accuracy: 0.0249 - precision: 0.9619 - recall: 0.9548 - f1_metrics: 0.9584 - val_loss: 2.3331 - val_accuracy: 0.0084 - val_precision: 0.6089 - val_recall: 0.5704 - val_f1_metrics: 0.5795\n",
            "Epoch 29/50\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1268 - accuracy: 0.0252 - precision: 0.9614 - recall: 0.9542 - f1_metrics: 0.9579 - val_loss: 2.3752 - val_accuracy: 0.0089 - val_precision: 0.5946 - val_recall: 0.5553 - val_f1_metrics: 0.5657\n",
            "Epoch 30/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1372 - accuracy: 0.0239 - precision: 0.9595 - recall: 0.9513 - f1_metrics: 0.9554 - val_loss: 2.3127 - val_accuracy: 0.0092 - val_precision: 0.6048 - val_recall: 0.5651 - val_f1_metrics: 0.5751\n",
            "Epoch 31/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1216 - accuracy: 0.0247 - precision: 0.9628 - recall: 0.9559 - f1_metrics: 0.9597 - val_loss: 2.3465 - val_accuracy: 0.0089 - val_precision: 0.6070 - val_recall: 0.5634 - val_f1_metrics: 0.5854\n",
            "Epoch 32/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1244 - accuracy: 0.0275 - precision: 0.9607 - recall: 0.9535 - f1_metrics: 0.9571 - val_loss: 2.4810 - val_accuracy: 0.0133 - val_precision: 0.6024 - val_recall: 0.5678 - val_f1_metrics: 0.5856\n",
            "Epoch 33/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1320 - accuracy: 0.0256 - precision: 0.9593 - recall: 0.9521 - f1_metrics: 0.9554 - val_loss: 2.3906 - val_accuracy: 0.0092 - val_precision: 0.6019 - val_recall: 0.5595 - val_f1_metrics: 0.5683\n",
            "Epoch 34/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1234 - accuracy: 0.0255 - precision: 0.9614 - recall: 0.9547 - f1_metrics: 0.9578 - val_loss: 2.3924 - val_accuracy: 0.0092 - val_precision: 0.6043 - val_recall: 0.5620 - val_f1_metrics: 0.5733\n",
            "Epoch 35/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1254 - accuracy: 0.0252 - precision: 0.9617 - recall: 0.9543 - f1_metrics: 0.9583 - val_loss: 2.3883 - val_accuracy: 0.0100 - val_precision: 0.6083 - val_recall: 0.5673 - val_f1_metrics: 0.5632\n",
            "Epoch 36/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1270 - accuracy: 0.0262 - precision: 0.9616 - recall: 0.9533 - f1_metrics: 0.9574 - val_loss: 2.4693 - val_accuracy: 0.0108 - val_precision: 0.6067 - val_recall: 0.5681 - val_f1_metrics: 0.5616\n",
            "Epoch 37/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1386 - accuracy: 0.0249 - precision: 0.9585 - recall: 0.9506 - f1_metrics: 0.9545 - val_loss: 2.3316 - val_accuracy: 0.0077 - val_precision: 0.6063 - val_recall: 0.5612 - val_f1_metrics: 0.5592\n",
            "Epoch 38/50\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1347 - accuracy: 0.0231 - precision: 0.9594 - recall: 0.9517 - f1_metrics: 0.9555 - val_loss: 2.2830 - val_accuracy: 0.0069 - val_precision: 0.6127 - val_recall: 0.5659 - val_f1_metrics: 0.5645\n",
            "Epoch 39/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1228 - accuracy: 0.0242 - precision: 0.9625 - recall: 0.9557 - f1_metrics: 0.9589 - val_loss: 2.4117 - val_accuracy: 0.0087 - val_precision: 0.5978 - val_recall: 0.5587 - val_f1_metrics: 0.5542\n",
            "Epoch 40/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1218 - accuracy: 0.0248 - precision: 0.9627 - recall: 0.9548 - f1_metrics: 0.9586 - val_loss: 2.5004 - val_accuracy: 0.0091 - val_precision: 0.5988 - val_recall: 0.5634 - val_f1_metrics: 0.5571\n",
            "Epoch 41/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1187 - accuracy: 0.0277 - precision: 0.9631 - recall: 0.9567 - f1_metrics: 0.9601 - val_loss: 2.3987 - val_accuracy: 0.0085 - val_precision: 0.6096 - val_recall: 0.5695 - val_f1_metrics: 0.5634\n",
            "Epoch 42/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1190 - accuracy: 0.0276 - precision: 0.9630 - recall: 0.9566 - f1_metrics: 0.9601 - val_loss: 2.4285 - val_accuracy: 0.0095 - val_precision: 0.6000 - val_recall: 0.5617 - val_f1_metrics: 0.5554\n",
            "Epoch 43/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1234 - accuracy: 0.0262 - precision: 0.9638 - recall: 0.9569 - f1_metrics: 0.9606 - val_loss: 2.3522 - val_accuracy: 0.0080 - val_precision: 0.6064 - val_recall: 0.5662 - val_f1_metrics: 0.5618\n",
            "Epoch 44/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1308 - accuracy: 0.0249 - precision: 0.9606 - recall: 0.9536 - f1_metrics: 0.9570 - val_loss: 2.3438 - val_accuracy: 0.0083 - val_precision: 0.6095 - val_recall: 0.5698 - val_f1_metrics: 0.5636\n",
            "Epoch 45/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1251 - accuracy: 0.0250 - precision: 0.9625 - recall: 0.9550 - f1_metrics: 0.9588 - val_loss: 2.3288 - val_accuracy: 0.0094 - val_precision: 0.6188 - val_recall: 0.5776 - val_f1_metrics: 0.5715\n",
            "Epoch 46/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1185 - accuracy: 0.0275 - precision: 0.9640 - recall: 0.9572 - f1_metrics: 0.9609 - val_loss: 2.4620 - val_accuracy: 0.0102 - val_precision: 0.6020 - val_recall: 0.5648 - val_f1_metrics: 0.5592\n",
            "Epoch 47/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1181 - accuracy: 0.0284 - precision: 0.9643 - recall: 0.9577 - f1_metrics: 0.9611 - val_loss: 2.3935 - val_accuracy: 0.0098 - val_precision: 0.6049 - val_recall: 0.5665 - val_f1_metrics: 0.5613\n",
            "Epoch 48/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1172 - accuracy: 0.0260 - precision: 0.9660 - recall: 0.9578 - f1_metrics: 0.9619 - val_loss: 2.4050 - val_accuracy: 0.0099 - val_precision: 0.6024 - val_recall: 0.5670 - val_f1_metrics: 0.5751\n",
            "Epoch 49/50\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1262 - accuracy: 0.0273 - precision: 0.9614 - recall: 0.9547 - f1_metrics: 0.9580 - val_loss: 2.3431 - val_accuracy: 0.0085 - val_precision: 0.6046 - val_recall: 0.5670 - val_f1_metrics: 0.5601\n",
            "Epoch 50/50\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1238 - accuracy: 0.0248 - precision: 0.9637 - recall: 0.9569 - f1_metrics: 0.9604 - val_loss: 2.3480 - val_accuracy: 0.0086 - val_precision: 0.6176 - val_recall: 0.5737 - val_f1_metrics: 0.5705\n",
            "VGGD16Custom | batch_size: 256 | epochs: 100\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1116 - accuracy: 0.0270 - precision: 0.9664 - recall: 0.9599 - f1_metrics: 0.9628 - val_loss: 2.4631 - val_accuracy: 0.0114 - val_precision: 0.6071 - val_recall: 0.5731 - val_f1_metrics: 0.5657\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1275 - accuracy: 0.0263 - precision: 0.9622 - recall: 0.9550 - f1_metrics: 0.9587 - val_loss: 2.3517 - val_accuracy: 0.0090 - val_precision: 0.6041 - val_recall: 0.5642 - val_f1_metrics: 0.5598\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1182 - accuracy: 0.0269 - precision: 0.9638 - recall: 0.9567 - f1_metrics: 0.9603 - val_loss: 2.4280 - val_accuracy: 0.0105 - val_precision: 0.6026 - val_recall: 0.5637 - val_f1_metrics: 0.5575\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1283 - accuracy: 0.0266 - precision: 0.9612 - recall: 0.9542 - f1_metrics: 0.9578 - val_loss: 2.3631 - val_accuracy: 0.0097 - val_precision: 0.6065 - val_recall: 0.5706 - val_f1_metrics: 0.5786\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1100 - accuracy: 0.0282 - precision: 0.9663 - recall: 0.9602 - f1_metrics: 0.9635 - val_loss: 2.4502 - val_accuracy: 0.0115 - val_precision: 0.6031 - val_recall: 0.5687 - val_f1_metrics: 0.5617\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1163 - accuracy: 0.0287 - precision: 0.9654 - recall: 0.9587 - f1_metrics: 0.9619 - val_loss: 2.3931 - val_accuracy: 0.0104 - val_precision: 0.6008 - val_recall: 0.5645 - val_f1_metrics: 0.5572\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1157 - accuracy: 0.0299 - precision: 0.9644 - recall: 0.9576 - f1_metrics: 0.9610 - val_loss: 2.5160 - val_accuracy: 0.0124 - val_precision: 0.6045 - val_recall: 0.5729 - val_f1_metrics: 0.5629\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1239 - accuracy: 0.0295 - precision: 0.9606 - recall: 0.9545 - f1_metrics: 0.9579 - val_loss: 2.4651 - val_accuracy: 0.0114 - val_precision: 0.6093 - val_recall: 0.5715 - val_f1_metrics: 0.5644\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1175 - accuracy: 0.0281 - precision: 0.9646 - recall: 0.9577 - f1_metrics: 0.9612 - val_loss: 2.4224 - val_accuracy: 0.0105 - val_precision: 0.6026 - val_recall: 0.5631 - val_f1_metrics: 0.5586\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1180 - accuracy: 0.0263 - precision: 0.9646 - recall: 0.9575 - f1_metrics: 0.9610 - val_loss: 2.3653 - val_accuracy: 0.0085 - val_precision: 0.6020 - val_recall: 0.5639 - val_f1_metrics: 0.5574\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1223 - accuracy: 0.0271 - precision: 0.9623 - recall: 0.9549 - f1_metrics: 0.9584 - val_loss: 2.3756 - val_accuracy: 0.0092 - val_precision: 0.6100 - val_recall: 0.5726 - val_f1_metrics: 0.5957\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1120 - accuracy: 0.0274 - precision: 0.9651 - recall: 0.9589 - f1_metrics: 0.9621 - val_loss: 2.4206 - val_accuracy: 0.0110 - val_precision: 0.6122 - val_recall: 0.5745 - val_f1_metrics: 0.5831\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1261 - accuracy: 0.0276 - precision: 0.9616 - recall: 0.9545 - f1_metrics: 0.9579 - val_loss: 2.4068 - val_accuracy: 0.0096 - val_precision: 0.6012 - val_recall: 0.5637 - val_f1_metrics: 0.5728\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1251 - accuracy: 0.0265 - precision: 0.9622 - recall: 0.9545 - f1_metrics: 0.9584 - val_loss: 2.4286 - val_accuracy: 0.0090 - val_precision: 0.5937 - val_recall: 0.5517 - val_f1_metrics: 0.5607\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1280 - accuracy: 0.0277 - precision: 0.9613 - recall: 0.9538 - f1_metrics: 0.9570 - val_loss: 2.4113 - val_accuracy: 0.0102 - val_precision: 0.5922 - val_recall: 0.5520 - val_f1_metrics: 0.5631\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1251 - accuracy: 0.0289 - precision: 0.9626 - recall: 0.9554 - f1_metrics: 0.9590 - val_loss: 2.4355 - val_accuracy: 0.0112 - val_precision: 0.6001 - val_recall: 0.5637 - val_f1_metrics: 0.5579\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1213 - accuracy: 0.0291 - precision: 0.9626 - recall: 0.9563 - f1_metrics: 0.9594 - val_loss: 2.3999 - val_accuracy: 0.0095 - val_precision: 0.6017 - val_recall: 0.5631 - val_f1_metrics: 0.5583\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1257 - accuracy: 0.0271 - precision: 0.9629 - recall: 0.9558 - f1_metrics: 0.9595 - val_loss: 2.3408 - val_accuracy: 0.0099 - val_precision: 0.6060 - val_recall: 0.5645 - val_f1_metrics: 0.5595\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 7s 61ms/step - loss: 0.1190 - accuracy: 0.0268 - precision: 0.9648 - recall: 0.9578 - f1_metrics: 0.9616 - val_loss: 2.3761 - val_accuracy: 0.0090 - val_precision: 0.6063 - val_recall: 0.5665 - val_f1_metrics: 0.5736\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1189 - accuracy: 0.0265 - precision: 0.9638 - recall: 0.9571 - f1_metrics: 0.9607 - val_loss: 2.4098 - val_accuracy: 0.0090 - val_precision: 0.6043 - val_recall: 0.5656 - val_f1_metrics: 0.5607\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1186 - accuracy: 0.0265 - precision: 0.9641 - recall: 0.9574 - f1_metrics: 0.9606 - val_loss: 2.4631 - val_accuracy: 0.0092 - val_precision: 0.5949 - val_recall: 0.5556 - val_f1_metrics: 0.5660\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1167 - accuracy: 0.0279 - precision: 0.9639 - recall: 0.9576 - f1_metrics: 0.9610 - val_loss: 2.4524 - val_accuracy: 0.0105 - val_precision: 0.5962 - val_recall: 0.5587 - val_f1_metrics: 0.5554\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1147 - accuracy: 0.0282 - precision: 0.9666 - recall: 0.9594 - f1_metrics: 0.9631 - val_loss: 2.4243 - val_accuracy: 0.0098 - val_precision: 0.5894 - val_recall: 0.5531 - val_f1_metrics: 0.5465\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 7s 61ms/step - loss: 0.1170 - accuracy: 0.0267 - precision: 0.9644 - recall: 0.9579 - f1_metrics: 0.9612 - val_loss: 2.3990 - val_accuracy: 0.0100 - val_precision: 0.5946 - val_recall: 0.5595 - val_f1_metrics: 0.5533\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1190 - accuracy: 0.0271 - precision: 0.9633 - recall: 0.9569 - f1_metrics: 0.9600 - val_loss: 2.4143 - val_accuracy: 0.0096 - val_precision: 0.6024 - val_recall: 0.5665 - val_f1_metrics: 0.5849\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1247 - accuracy: 0.0280 - precision: 0.9631 - recall: 0.9563 - f1_metrics: 0.9596 - val_loss: 2.3687 - val_accuracy: 0.0090 - val_precision: 0.6059 - val_recall: 0.5667 - val_f1_metrics: 0.5618\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1148 - accuracy: 0.0278 - precision: 0.9652 - recall: 0.9590 - f1_metrics: 0.9620 - val_loss: 2.4373 - val_accuracy: 0.0090 - val_precision: 0.6066 - val_recall: 0.5706 - val_f1_metrics: 0.5889\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1222 - accuracy: 0.0291 - precision: 0.9629 - recall: 0.9563 - f1_metrics: 0.9598 - val_loss: 2.3887 - val_accuracy: 0.0114 - val_precision: 0.6013 - val_recall: 0.5614 - val_f1_metrics: 0.5573\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1113 - accuracy: 0.0303 - precision: 0.9669 - recall: 0.9617 - f1_metrics: 0.9643 - val_loss: 2.4837 - val_accuracy: 0.0096 - val_precision: 0.5897 - val_recall: 0.5578 - val_f1_metrics: 0.5504\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1128 - accuracy: 0.0322 - precision: 0.9648 - recall: 0.9588 - f1_metrics: 0.9620 - val_loss: 2.5011 - val_accuracy: 0.0113 - val_precision: 0.5969 - val_recall: 0.5614 - val_f1_metrics: 0.5554\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1159 - accuracy: 0.0314 - precision: 0.9646 - recall: 0.9584 - f1_metrics: 0.9613 - val_loss: 2.5080 - val_accuracy: 0.0114 - val_precision: 0.6004 - val_recall: 0.5667 - val_f1_metrics: 0.5594\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1204 - accuracy: 0.0280 - precision: 0.9637 - recall: 0.9566 - f1_metrics: 0.9602 - val_loss: 2.4360 - val_accuracy: 0.0126 - val_precision: 0.6089 - val_recall: 0.5712 - val_f1_metrics: 0.5653\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1166 - accuracy: 0.0287 - precision: 0.9640 - recall: 0.9575 - f1_metrics: 0.9606 - val_loss: 2.3994 - val_accuracy: 0.0096 - val_precision: 0.6043 - val_recall: 0.5642 - val_f1_metrics: 0.5600\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1178 - accuracy: 0.0286 - precision: 0.9639 - recall: 0.9570 - f1_metrics: 0.9607 - val_loss: 2.4063 - val_accuracy: 0.0105 - val_precision: 0.6058 - val_recall: 0.5678 - val_f1_metrics: 0.5741\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1069 - accuracy: 0.0322 - precision: 0.9674 - recall: 0.9620 - f1_metrics: 0.9647 - val_loss: 2.5514 - val_accuracy: 0.0123 - val_precision: 0.5998 - val_recall: 0.5645 - val_f1_metrics: 0.5581\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1150 - accuracy: 0.0322 - precision: 0.9651 - recall: 0.9591 - f1_metrics: 0.9622 - val_loss: 2.3947 - val_accuracy: 0.0099 - val_precision: 0.6014 - val_recall: 0.5617 - val_f1_metrics: 0.5720\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1194 - accuracy: 0.0280 - precision: 0.9629 - recall: 0.9567 - f1_metrics: 0.9597 - val_loss: 2.4583 - val_accuracy: 0.0101 - val_precision: 0.5999 - val_recall: 0.5598 - val_f1_metrics: 0.5545\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1087 - accuracy: 0.0298 - precision: 0.9678 - recall: 0.9614 - f1_metrics: 0.9645 - val_loss: 2.5450 - val_accuracy: 0.0123 - val_precision: 0.6034 - val_recall: 0.5659 - val_f1_metrics: 0.5604\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1236 - accuracy: 0.0284 - precision: 0.9636 - recall: 0.9571 - f1_metrics: 0.9599 - val_loss: 2.4073 - val_accuracy: 0.0082 - val_precision: 0.6045 - val_recall: 0.5639 - val_f1_metrics: 0.5716\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1163 - accuracy: 0.0287 - precision: 0.9640 - recall: 0.9575 - f1_metrics: 0.9610 - val_loss: 2.4095 - val_accuracy: 0.0110 - val_precision: 0.5989 - val_recall: 0.5626 - val_f1_metrics: 0.5555\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1185 - accuracy: 0.0287 - precision: 0.9635 - recall: 0.9576 - f1_metrics: 0.9602 - val_loss: 2.3945 - val_accuracy: 0.0111 - val_precision: 0.6042 - val_recall: 0.5673 - val_f1_metrics: 0.5614\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1146 - accuracy: 0.0286 - precision: 0.9659 - recall: 0.9592 - f1_metrics: 0.9620 - val_loss: 2.5025 - val_accuracy: 0.0131 - val_precision: 0.6058 - val_recall: 0.5670 - val_f1_metrics: 0.5607\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1249 - accuracy: 0.0304 - precision: 0.9625 - recall: 0.9561 - f1_metrics: 0.9596 - val_loss: 2.4173 - val_accuracy: 0.0103 - val_precision: 0.6002 - val_recall: 0.5648 - val_f1_metrics: 0.5702\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1091 - accuracy: 0.0301 - precision: 0.9678 - recall: 0.9614 - f1_metrics: 0.9647 - val_loss: 2.4625 - val_accuracy: 0.0117 - val_precision: 0.6066 - val_recall: 0.5754 - val_f1_metrics: 0.5682\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1152 - accuracy: 0.0300 - precision: 0.9663 - recall: 0.9599 - f1_metrics: 0.9631 - val_loss: 2.4328 - val_accuracy: 0.0117 - val_precision: 0.6056 - val_recall: 0.5681 - val_f1_metrics: 0.5769\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 7s 61ms/step - loss: 0.1173 - accuracy: 0.0293 - precision: 0.9650 - recall: 0.9590 - f1_metrics: 0.9623 - val_loss: 2.4135 - val_accuracy: 0.0105 - val_precision: 0.6055 - val_recall: 0.5667 - val_f1_metrics: 0.5617\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1112 - accuracy: 0.0294 - precision: 0.9660 - recall: 0.9595 - f1_metrics: 0.9628 - val_loss: 2.4469 - val_accuracy: 0.0114 - val_precision: 0.6051 - val_recall: 0.5653 - val_f1_metrics: 0.5626\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1050 - accuracy: 0.0315 - precision: 0.9670 - recall: 0.9609 - f1_metrics: 0.9639 - val_loss: 2.4602 - val_accuracy: 0.0100 - val_precision: 0.6046 - val_recall: 0.5709 - val_f1_metrics: 0.5620\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1082 - accuracy: 0.0308 - precision: 0.9669 - recall: 0.9612 - f1_metrics: 0.9636 - val_loss: 2.4747 - val_accuracy: 0.0116 - val_precision: 0.6117 - val_recall: 0.5759 - val_f1_metrics: 0.5836\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1176 - accuracy: 0.0312 - precision: 0.9645 - recall: 0.9583 - f1_metrics: 0.9613 - val_loss: 2.4593 - val_accuracy: 0.0127 - val_precision: 0.6010 - val_recall: 0.5695 - val_f1_metrics: 0.5902\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1128 - accuracy: 0.0316 - precision: 0.9656 - recall: 0.9596 - f1_metrics: 0.9626 - val_loss: 2.5178 - val_accuracy: 0.0143 - val_precision: 0.6005 - val_recall: 0.5659 - val_f1_metrics: 0.5590\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1223 - accuracy: 0.0300 - precision: 0.9629 - recall: 0.9565 - f1_metrics: 0.9599 - val_loss: 2.4806 - val_accuracy: 0.0115 - val_precision: 0.6057 - val_recall: 0.5667 - val_f1_metrics: 0.5909\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1173 - accuracy: 0.0292 - precision: 0.9639 - recall: 0.9576 - f1_metrics: 0.9610 - val_loss: 2.4122 - val_accuracy: 0.0119 - val_precision: 0.6051 - val_recall: 0.5709 - val_f1_metrics: 0.5636\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1098 - accuracy: 0.0298 - precision: 0.9666 - recall: 0.9612 - f1_metrics: 0.9639 - val_loss: 2.4448 - val_accuracy: 0.0109 - val_precision: 0.6033 - val_recall: 0.5648 - val_f1_metrics: 0.5598\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1101 - accuracy: 0.0323 - precision: 0.9677 - recall: 0.9614 - f1_metrics: 0.9645 - val_loss: 2.4360 - val_accuracy: 0.0139 - val_precision: 0.6126 - val_recall: 0.5745 - val_f1_metrics: 0.5803\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1205 - accuracy: 0.0302 - precision: 0.9630 - recall: 0.9564 - f1_metrics: 0.9596 - val_loss: 2.4586 - val_accuracy: 0.0099 - val_precision: 0.6061 - val_recall: 0.5720 - val_f1_metrics: 0.5792\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1182 - accuracy: 0.0302 - precision: 0.9630 - recall: 0.9564 - f1_metrics: 0.9600 - val_loss: 2.4408 - val_accuracy: 0.0107 - val_precision: 0.6154 - val_recall: 0.5756 - val_f1_metrics: 0.5706\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1070 - accuracy: 0.0320 - precision: 0.9676 - recall: 0.9618 - f1_metrics: 0.9650 - val_loss: 2.5355 - val_accuracy: 0.0122 - val_precision: 0.6136 - val_recall: 0.5762 - val_f1_metrics: 0.5817\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1161 - accuracy: 0.0315 - precision: 0.9653 - recall: 0.9591 - f1_metrics: 0.9625 - val_loss: 2.4193 - val_accuracy: 0.0104 - val_precision: 0.6120 - val_recall: 0.5692 - val_f1_metrics: 0.5658\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1030 - accuracy: 0.0343 - precision: 0.9691 - recall: 0.9627 - f1_metrics: 0.9661 - val_loss: 2.5484 - val_accuracy: 0.0153 - val_precision: 0.6067 - val_recall: 0.5729 - val_f1_metrics: 0.5652\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1203 - accuracy: 0.0337 - precision: 0.9644 - recall: 0.9591 - f1_metrics: 0.9615 - val_loss: 2.4364 - val_accuracy: 0.0122 - val_precision: 0.6050 - val_recall: 0.5701 - val_f1_metrics: 0.5813\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1213 - accuracy: 0.0311 - precision: 0.9634 - recall: 0.9571 - f1_metrics: 0.9605 - val_loss: 2.4911 - val_accuracy: 0.0117 - val_precision: 0.5982 - val_recall: 0.5575 - val_f1_metrics: 0.5684\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1115 - accuracy: 0.0326 - precision: 0.9668 - recall: 0.9608 - f1_metrics: 0.9640 - val_loss: 2.5431 - val_accuracy: 0.0109 - val_precision: 0.5960 - val_recall: 0.5570 - val_f1_metrics: 0.5644\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1051 - accuracy: 0.0326 - precision: 0.9686 - recall: 0.9628 - f1_metrics: 0.9659 - val_loss: 2.4596 - val_accuracy: 0.0119 - val_precision: 0.6018 - val_recall: 0.5673 - val_f1_metrics: 0.5590\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1083 - accuracy: 0.0349 - precision: 0.9676 - recall: 0.9618 - f1_metrics: 0.9647 - val_loss: 2.5187 - val_accuracy: 0.0109 - val_precision: 0.5984 - val_recall: 0.5626 - val_f1_metrics: 0.5812\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1186 - accuracy: 0.0305 - precision: 0.9637 - recall: 0.9577 - f1_metrics: 0.9610 - val_loss: 2.4640 - val_accuracy: 0.0125 - val_precision: 0.6053 - val_recall: 0.5645 - val_f1_metrics: 0.5623\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1030 - accuracy: 0.0312 - precision: 0.9683 - recall: 0.9628 - f1_metrics: 0.9656 - val_loss: 2.5605 - val_accuracy: 0.0120 - val_precision: 0.6030 - val_recall: 0.5662 - val_f1_metrics: 0.5620\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1122 - accuracy: 0.0328 - precision: 0.9662 - recall: 0.9601 - f1_metrics: 0.9625 - val_loss: 2.4432 - val_accuracy: 0.0106 - val_precision: 0.6088 - val_recall: 0.5681 - val_f1_metrics: 0.5784\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1320 - accuracy: 0.0271 - precision: 0.9616 - recall: 0.9535 - f1_metrics: 0.9574 - val_loss: 2.3632 - val_accuracy: 0.0095 - val_precision: 0.6131 - val_recall: 0.5717 - val_f1_metrics: 0.5966\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1138 - accuracy: 0.0296 - precision: 0.9650 - recall: 0.9582 - f1_metrics: 0.9616 - val_loss: 2.4426 - val_accuracy: 0.0124 - val_precision: 0.6044 - val_recall: 0.5670 - val_f1_metrics: 0.5758\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1100 - accuracy: 0.0323 - precision: 0.9658 - recall: 0.9605 - f1_metrics: 0.9632 - val_loss: 2.4350 - val_accuracy: 0.0117 - val_precision: 0.6024 - val_recall: 0.5639 - val_f1_metrics: 0.5707\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1068 - accuracy: 0.0344 - precision: 0.9681 - recall: 0.9624 - f1_metrics: 0.9653 - val_loss: 2.4715 - val_accuracy: 0.0106 - val_precision: 0.6015 - val_recall: 0.5715 - val_f1_metrics: 0.5870\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1094 - accuracy: 0.0317 - precision: 0.9683 - recall: 0.9623 - f1_metrics: 0.9653 - val_loss: 2.3794 - val_accuracy: 0.0121 - val_precision: 0.6033 - val_recall: 0.5662 - val_f1_metrics: 0.5591\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1097 - accuracy: 0.0319 - precision: 0.9665 - recall: 0.9610 - f1_metrics: 0.9638 - val_loss: 2.5203 - val_accuracy: 0.0119 - val_precision: 0.6108 - val_recall: 0.5720 - val_f1_metrics: 0.5812\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1064 - accuracy: 0.0330 - precision: 0.9673 - recall: 0.9628 - f1_metrics: 0.9651 - val_loss: 2.4717 - val_accuracy: 0.0126 - val_precision: 0.6079 - val_recall: 0.5712 - val_f1_metrics: 0.5765\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1055 - accuracy: 0.0351 - precision: 0.9681 - recall: 0.9624 - f1_metrics: 0.9653 - val_loss: 2.5348 - val_accuracy: 0.0126 - val_precision: 0.6015 - val_recall: 0.5665 - val_f1_metrics: 0.5888\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1112 - accuracy: 0.0352 - precision: 0.9674 - recall: 0.9615 - f1_metrics: 0.9645 - val_loss: 2.4871 - val_accuracy: 0.0129 - val_precision: 0.6015 - val_recall: 0.5662 - val_f1_metrics: 0.5888\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1134 - accuracy: 0.0352 - precision: 0.9654 - recall: 0.9593 - f1_metrics: 0.9626 - val_loss: 2.5693 - val_accuracy: 0.0124 - val_precision: 0.6022 - val_recall: 0.5706 - val_f1_metrics: 0.5767\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1087 - accuracy: 0.0360 - precision: 0.9675 - recall: 0.9626 - f1_metrics: 0.9651 - val_loss: 2.4642 - val_accuracy: 0.0107 - val_precision: 0.6051 - val_recall: 0.5653 - val_f1_metrics: 0.5900\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1087 - accuracy: 0.0326 - precision: 0.9664 - recall: 0.9596 - f1_metrics: 0.9631 - val_loss: 2.4103 - val_accuracy: 0.0111 - val_precision: 0.6007 - val_recall: 0.5651 - val_f1_metrics: 0.5879\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1105 - accuracy: 0.0328 - precision: 0.9661 - recall: 0.9600 - f1_metrics: 0.9633 - val_loss: 2.5019 - val_accuracy: 0.0116 - val_precision: 0.6086 - val_recall: 0.5698 - val_f1_metrics: 0.5792\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1070 - accuracy: 0.0337 - precision: 0.9683 - recall: 0.9619 - f1_metrics: 0.9648 - val_loss: 2.6026 - val_accuracy: 0.0121 - val_precision: 0.5955 - val_recall: 0.5620 - val_f1_metrics: 0.5695\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1279 - accuracy: 0.0322 - precision: 0.9614 - recall: 0.9552 - f1_metrics: 0.9582 - val_loss: 2.3864 - val_accuracy: 0.0100 - val_precision: 0.6062 - val_recall: 0.5645 - val_f1_metrics: 0.5754\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1095 - accuracy: 0.0323 - precision: 0.9668 - recall: 0.9613 - f1_metrics: 0.9639 - val_loss: 2.4421 - val_accuracy: 0.0126 - val_precision: 0.6069 - val_recall: 0.5704 - val_f1_metrics: 0.5932\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1102 - accuracy: 0.0334 - precision: 0.9675 - recall: 0.9626 - f1_metrics: 0.9653 - val_loss: 2.4269 - val_accuracy: 0.0123 - val_precision: 0.6051 - val_recall: 0.5695 - val_f1_metrics: 0.5975\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.0968 - accuracy: 0.0369 - precision: 0.9698 - recall: 0.9643 - f1_metrics: 0.9671 - val_loss: 2.5527 - val_accuracy: 0.0152 - val_precision: 0.6032 - val_recall: 0.5676 - val_f1_metrics: 0.5756\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1030 - accuracy: 0.0365 - precision: 0.9698 - recall: 0.9649 - f1_metrics: 0.9666 - val_loss: 2.4868 - val_accuracy: 0.0137 - val_precision: 0.6133 - val_recall: 0.5793 - val_f1_metrics: 0.5859\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1130 - accuracy: 0.0341 - precision: 0.9662 - recall: 0.9605 - f1_metrics: 0.9636 - val_loss: 2.5416 - val_accuracy: 0.0146 - val_precision: 0.6050 - val_recall: 0.5692 - val_f1_metrics: 0.5772\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1065 - accuracy: 0.0366 - precision: 0.9672 - recall: 0.9611 - f1_metrics: 0.9644 - val_loss: 2.4948 - val_accuracy: 0.0133 - val_precision: 0.6087 - val_recall: 0.5765 - val_f1_metrics: 0.5825\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1262 - accuracy: 0.0328 - precision: 0.9613 - recall: 0.9557 - f1_metrics: 0.9584 - val_loss: 2.3366 - val_accuracy: 0.0107 - val_precision: 0.6200 - val_recall: 0.5751 - val_f1_metrics: 0.5723\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1200 - accuracy: 0.0306 - precision: 0.9644 - recall: 0.9574 - f1_metrics: 0.9608 - val_loss: 2.3643 - val_accuracy: 0.0097 - val_precision: 0.6083 - val_recall: 0.5690 - val_f1_metrics: 0.5786\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1143 - accuracy: 0.0327 - precision: 0.9660 - recall: 0.9596 - f1_metrics: 0.9625 - val_loss: 2.3468 - val_accuracy: 0.0099 - val_precision: 0.6080 - val_recall: 0.5670 - val_f1_metrics: 0.5776\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1173 - accuracy: 0.0318 - precision: 0.9660 - recall: 0.9592 - f1_metrics: 0.9624 - val_loss: 2.5018 - val_accuracy: 0.0142 - val_precision: 0.6006 - val_recall: 0.5639 - val_f1_metrics: 0.5728\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 7s 63ms/step - loss: 0.1155 - accuracy: 0.0322 - precision: 0.9646 - recall: 0.9586 - f1_metrics: 0.9619 - val_loss: 2.3804 - val_accuracy: 0.0109 - val_precision: 0.6028 - val_recall: 0.5645 - val_f1_metrics: 0.5885\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.0957 - accuracy: 0.0348 - precision: 0.9710 - recall: 0.9654 - f1_metrics: 0.9678 - val_loss: 2.4388 - val_accuracy: 0.0125 - val_precision: 0.6062 - val_recall: 0.5692 - val_f1_metrics: 0.5778\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1214 - accuracy: 0.0323 - precision: 0.9630 - recall: 0.9557 - f1_metrics: 0.9596 - val_loss: 2.4094 - val_accuracy: 0.0114 - val_precision: 0.6026 - val_recall: 0.5578 - val_f1_metrics: 0.5546\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1102 - accuracy: 0.0329 - precision: 0.9680 - recall: 0.9626 - f1_metrics: 0.9651 - val_loss: 2.4040 - val_accuracy: 0.0103 - val_precision: 0.6055 - val_recall: 0.5667 - val_f1_metrics: 0.5734\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1159 - accuracy: 0.0328 - precision: 0.9655 - recall: 0.9591 - f1_metrics: 0.9620 - val_loss: 2.4582 - val_accuracy: 0.0138 - val_precision: 0.5979 - val_recall: 0.5564 - val_f1_metrics: 0.5648\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1142 - accuracy: 0.0335 - precision: 0.9653 - recall: 0.9587 - f1_metrics: 0.9623 - val_loss: 2.4785 - val_accuracy: 0.0112 - val_precision: 0.6093 - val_recall: 0.5670 - val_f1_metrics: 0.6013\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 7s 62ms/step - loss: 0.1108 - accuracy: 0.0330 - precision: 0.9675 - recall: 0.9619 - f1_metrics: 0.9647 - val_loss: 2.4936 - val_accuracy: 0.0127 - val_precision: 0.6058 - val_recall: 0.5648 - val_f1_metrics: 0.5900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrW6ZyosxHUl"
      },
      "source": [
        "## Resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QguVswFY1Opc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4598e9-284f-49e8-f20d-a335023be16c"
      },
      "source": [
        "histories = glob.glob('{}/hist_*.json'.format(dirname))\n",
        "histories"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_ShallowCNN_128_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_ShallowCNN_128_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_ShallowCNN_128_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_ShallowCNN_256_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_ShallowCNN_256_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_ShallowCNN_256_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_DeepCNN_128_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_DeepCNN_128_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_DeepCNN_128_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_DeepCNN_256_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_DeepCNN_256_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_DeepCNN_256_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGA11_128_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGA11_128_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGA11_128_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGA11_256_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGA11_256_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGA11_256_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGALRN11_128_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGALRN11_128_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGALRN11_128_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGALRN11_256_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGALRN11_256_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGALRN11_256_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGB13_128_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGB13_128_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGB13_128_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGB13_256_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGB13_256_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGB13_256_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGC16_128_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGC16_128_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGC16_128_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGC16_256_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGC16_256_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGC16_256_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGD16_128_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGD16_128_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGD16_128_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGD16_256_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGD16_256_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGD16_256_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGE19_128_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGE19_128_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGE19_128_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGE19_256_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGE19_256_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGE19_256_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_DeepCNNCustom_128_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_DeepCNNCustom_128_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_DeepCNNCustom_128_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_DeepCNNCustom_256_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_DeepCNNCustom_256_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_DeepCNNCustom_256_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGE19Custom_128_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGE19Custom_128_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGE19Custom_128_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGE19Custom_256_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGE19Custom_256_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGE19Custom_256_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGD16Custom_128_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGD16Custom_128_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGD16Custom_128_100.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGD16Custom_256_30.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGD16Custom_256_50.json',\n",
              " '/content/drive/My Drive/Ensino/UFRN 2016.1/2020.6/Aprendizado Profundo/projeto_final/models/hist_VGGD16Custom_256_100.json']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESu4TXlubZ98"
      },
      "source": [
        "result = []\n",
        "for f in histories:\n",
        "    with open(f, \"rb\") as infile:\n",
        "        result.append(json.load(infile))"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNxSAnC-cJsh"
      },
      "source": [
        "with open(\"{}/merged_file.json\".format(dirname), \"w\") as outfile:\n",
        "     json.dump(result, outfile)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjdhfl-sc9M_",
        "outputId": "9e2a5c4c-b20d-4a02-e6e5-4eb6f43388f6"
      },
      "source": [
        "result[0]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'ShallowCNN_128_30',\n",
              " 'metrics': {'accuracy': 0.00719535443931818,\n",
              "  'f1_metrics': 0.9912812113761902,\n",
              "  'loss': 0.038720037788152695,\n",
              "  'precision': 0.9919453263282776,\n",
              "  'recall': 0.9909088015556335,\n",
              "  'val_accuracy': 0.0005572583177126944,\n",
              "  'val_f1_metrics': 0.5132482051849365,\n",
              "  'val_loss': 2.0932767391204834,\n",
              "  'val_precision': 0.5480329394340515,\n",
              "  'val_recall': 0.50069659948349},\n",
              " 'name': 'ShallowCNN',\n",
              " 'params': {'batch_size': 128, 'epochs': 30, 'steps': 225}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "osXg4JJCcagC",
        "outputId": "8e4e5a04-cecf-47ca-b946-e2e98b0f1771"
      },
      "source": [
        "result[0]['id']"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ShallowCNN_128_30'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPajCVwmc1DS"
      },
      "source": [
        "columns = [\n",
        "  'id',\n",
        "  'name',\n",
        "  'accuracy',\n",
        "  'f1_metrics',\n",
        "  'loss',\n",
        "  'precision',\n",
        "  'recall',\n",
        "  'val_accuracy',\n",
        "  'val_f1_metrics',\n",
        "  'val_loss',\n",
        "  'val_precision',\n",
        "  'val_recall',\n",
        "  'batch_size',\n",
        "  'epochs',\n",
        "  'steps',\n",
        "]\n",
        "\n",
        "csv_data = []\n",
        "\n",
        "for hist in result:\n",
        "  data = [\n",
        "    hist['id'],\n",
        "    hist['name'],\n",
        "    hist['metrics']['accuracy'],\n",
        "    hist['metrics']['f1_metrics'],\n",
        "    hist['metrics']['loss'],\n",
        "    hist['metrics']['precision'],\n",
        "    hist['metrics']['recall'],\n",
        "    hist['metrics']['val_accuracy'],\n",
        "    hist['metrics']['val_f1_metrics'],\n",
        "    hist['metrics']['val_loss'],\n",
        "    hist['metrics']['val_precision'],\n",
        "    hist['metrics']['val_recall'],\n",
        "    hist['params']['batch_size'],\n",
        "    hist['params']['epochs'],\n",
        "    hist['params']['steps'],\n",
        "  ]\n",
        "  csv_data.append(data)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFVhwIaPdbR5"
      },
      "source": [
        "df = pd.DataFrame(csv_data, columns=columns)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "9_SlVJujde_M",
        "outputId": "fd35a0aa-c7e6-4c66-a859-922498df38b7"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_metrics</th>\n",
              "      <th>loss</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_f1_metrics</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>steps</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ShallowCNN_128_30</td>\n",
              "      <td>ShallowCNN</td>\n",
              "      <td>0.007195</td>\n",
              "      <td>0.991281</td>\n",
              "      <td>0.038720</td>\n",
              "      <td>0.991945</td>\n",
              "      <td>0.990909</td>\n",
              "      <td>0.000557</td>\n",
              "      <td>0.513248</td>\n",
              "      <td>2.093277</td>\n",
              "      <td>0.548033</td>\n",
              "      <td>0.500697</td>\n",
              "      <td>128</td>\n",
              "      <td>30</td>\n",
              "      <td>225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ShallowCNN_128_50</td>\n",
              "      <td>ShallowCNN</td>\n",
              "      <td>0.017103</td>\n",
              "      <td>0.994669</td>\n",
              "      <td>0.021875</td>\n",
              "      <td>0.994774</td>\n",
              "      <td>0.994531</td>\n",
              "      <td>0.001831</td>\n",
              "      <td>0.536337</td>\n",
              "      <td>2.116821</td>\n",
              "      <td>0.574442</td>\n",
              "      <td>0.523544</td>\n",
              "      <td>128</td>\n",
              "      <td>50</td>\n",
              "      <td>225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ShallowCNN_128_100</td>\n",
              "      <td>ShallowCNN</td>\n",
              "      <td>0.039425</td>\n",
              "      <td>0.996770</td>\n",
              "      <td>0.009355</td>\n",
              "      <td>0.996864</td>\n",
              "      <td>0.996656</td>\n",
              "      <td>0.003662</td>\n",
              "      <td>0.549105</td>\n",
              "      <td>2.199910</td>\n",
              "      <td>0.573171</td>\n",
              "      <td>0.523823</td>\n",
              "      <td>128</td>\n",
              "      <td>100</td>\n",
              "      <td>225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ShallowCNN_256_30</td>\n",
              "      <td>ShallowCNN</td>\n",
              "      <td>0.048910</td>\n",
              "      <td>0.997338</td>\n",
              "      <td>0.006182</td>\n",
              "      <td>0.997422</td>\n",
              "      <td>0.997213</td>\n",
              "      <td>0.004299</td>\n",
              "      <td>0.546227</td>\n",
              "      <td>2.272174</td>\n",
              "      <td>0.578078</td>\n",
              "      <td>0.536361</td>\n",
              "      <td>256</td>\n",
              "      <td>30</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ShallowCNN_256_50</td>\n",
              "      <td>ShallowCNN</td>\n",
              "      <td>0.057020</td>\n",
              "      <td>0.996906</td>\n",
              "      <td>0.007185</td>\n",
              "      <td>0.996934</td>\n",
              "      <td>0.996830</td>\n",
              "      <td>0.005254</td>\n",
              "      <td>0.514100</td>\n",
              "      <td>2.346944</td>\n",
              "      <td>0.560864</td>\n",
              "      <td>0.513514</td>\n",
              "      <td>256</td>\n",
              "      <td>50</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id        name  accuracy  ...  batch_size  epochs  steps\n",
              "0   ShallowCNN_128_30  ShallowCNN  0.007195  ...         128      30    225\n",
              "1   ShallowCNN_128_50  ShallowCNN  0.017103  ...         128      50    225\n",
              "2  ShallowCNN_128_100  ShallowCNN  0.039425  ...         128     100    225\n",
              "3   ShallowCNN_256_30  ShallowCNN  0.048910  ...         256      30    113\n",
              "4   ShallowCNN_256_50  ShallowCNN  0.057020  ...         256      50    113\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIp2TP-7df3K"
      },
      "source": [
        "df['precision_max'] = df.groupby(['name'])['precision'].transform(max)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "mW7i9lUDe5TB",
        "outputId": "3a61aaf3-4050-4842-9d6b-2778a3e0169c"
      },
      "source": [
        "df_filter = df[df['precision'] != 0]\n",
        "df_filter = df_filter[df_filter['precision_max'] == df_filter['precision']]\n",
        "df_filter"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_metrics</th>\n",
              "      <th>loss</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_f1_metrics</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>steps</th>\n",
              "      <th>precision_max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ShallowCNN_256_100</td>\n",
              "      <td>ShallowCNN</td>\n",
              "      <td>0.071167</td>\n",
              "      <td>0.997839</td>\n",
              "      <td>0.004761</td>\n",
              "      <td>0.997944</td>\n",
              "      <td>0.997701</td>\n",
              "      <td>0.002189</td>\n",
              "      <td>0.525606</td>\n",
              "      <td>2.057211</td>\n",
              "      <td>0.569493</td>\n",
              "      <td>0.503483</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>113</td>\n",
              "      <td>0.997944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>DeepCNN_256_100</td>\n",
              "      <td>DeepCNN</td>\n",
              "      <td>0.043610</td>\n",
              "      <td>0.994259</td>\n",
              "      <td>0.014876</td>\n",
              "      <td>0.994459</td>\n",
              "      <td>0.993974</td>\n",
              "      <td>0.011384</td>\n",
              "      <td>0.616898</td>\n",
              "      <td>2.570012</td>\n",
              "      <td>0.621567</td>\n",
              "      <td>0.605461</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>113</td>\n",
              "      <td>0.994459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>VGGALRN11_256_100</td>\n",
              "      <td>VGGALRN11</td>\n",
              "      <td>0.119918</td>\n",
              "      <td>0.997717</td>\n",
              "      <td>0.005501</td>\n",
              "      <td>0.997979</td>\n",
              "      <td>0.997422</td>\n",
              "      <td>0.070891</td>\n",
              "      <td>0.561648</td>\n",
              "      <td>4.273236</td>\n",
              "      <td>0.589599</td>\n",
              "      <td>0.581220</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>113</td>\n",
              "      <td>0.997979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>DeepCNNCustom_256_100</td>\n",
              "      <td>DeepCNNCustom</td>\n",
              "      <td>0.040132</td>\n",
              "      <td>0.985722</td>\n",
              "      <td>0.040009</td>\n",
              "      <td>0.986818</td>\n",
              "      <td>0.985649</td>\n",
              "      <td>0.008598</td>\n",
              "      <td>0.613123</td>\n",
              "      <td>2.202486</td>\n",
              "      <td>0.622566</td>\n",
              "      <td>0.605740</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>113</td>\n",
              "      <td>0.986818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>VGGE19Custom_256_100</td>\n",
              "      <td>VGGE19Custom</td>\n",
              "      <td>0.190274</td>\n",
              "      <td>0.997700</td>\n",
              "      <td>0.004351</td>\n",
              "      <td>0.997840</td>\n",
              "      <td>0.997527</td>\n",
              "      <td>0.104048</td>\n",
              "      <td>0.602323</td>\n",
              "      <td>4.385242</td>\n",
              "      <td>0.621461</td>\n",
              "      <td>0.611591</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>113</td>\n",
              "      <td>0.997840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>VGGD16Custom_256_100</td>\n",
              "      <td>VGGD16Custom</td>\n",
              "      <td>0.033011</td>\n",
              "      <td>0.964722</td>\n",
              "      <td>0.110778</td>\n",
              "      <td>0.967454</td>\n",
              "      <td>0.961893</td>\n",
              "      <td>0.012737</td>\n",
              "      <td>0.589995</td>\n",
              "      <td>2.493613</td>\n",
              "      <td>0.605798</td>\n",
              "      <td>0.564781</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>113</td>\n",
              "      <td>0.967454</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       id           name  ...  steps  precision_max\n",
              "5      ShallowCNN_256_100     ShallowCNN  ...    113       0.997944\n",
              "11        DeepCNN_256_100        DeepCNN  ...    113       0.994459\n",
              "23      VGGALRN11_256_100      VGGALRN11  ...    113       0.997979\n",
              "53  DeepCNNCustom_256_100  DeepCNNCustom  ...    113       0.986818\n",
              "59   VGGE19Custom_256_100   VGGE19Custom  ...    113       0.997840\n",
              "65   VGGD16Custom_256_100   VGGD16Custom  ...    113       0.967454\n",
              "\n",
              "[6 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "z9emgJjugJJF",
        "outputId": "36cfc300-d68a-46fc-90b8-28109783d2d3"
      },
      "source": [
        "grouped_df = df.groupby(['name'])\n",
        "maximums = grouped_df.max()\n",
        "maximums = maximums.reset_index()\n",
        "maximums"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>id</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_metrics</th>\n",
              "      <th>loss</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_f1_metrics</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>steps</th>\n",
              "      <th>precision_max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DeepCNN</td>\n",
              "      <td>DeepCNN_256_50</td>\n",
              "      <td>0.043610</td>\n",
              "      <td>0.994259</td>\n",
              "      <td>0.149134</td>\n",
              "      <td>0.994459</td>\n",
              "      <td>0.993974</td>\n",
              "      <td>0.011384</td>\n",
              "      <td>0.630717</td>\n",
              "      <td>2.570012</td>\n",
              "      <td>0.626176</td>\n",
              "      <td>0.611870</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>225</td>\n",
              "      <td>0.994459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DeepCNNCustom</td>\n",
              "      <td>DeepCNNCustom_256_50</td>\n",
              "      <td>0.040132</td>\n",
              "      <td>0.985722</td>\n",
              "      <td>0.396511</td>\n",
              "      <td>0.986818</td>\n",
              "      <td>0.985649</td>\n",
              "      <td>0.008598</td>\n",
              "      <td>0.613123</td>\n",
              "      <td>2.202486</td>\n",
              "      <td>0.653329</td>\n",
              "      <td>0.605740</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>225</td>\n",
              "      <td>0.986818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ShallowCNN</td>\n",
              "      <td>ShallowCNN_256_50</td>\n",
              "      <td>0.071167</td>\n",
              "      <td>0.997839</td>\n",
              "      <td>0.038720</td>\n",
              "      <td>0.997944</td>\n",
              "      <td>0.997701</td>\n",
              "      <td>0.005254</td>\n",
              "      <td>0.549105</td>\n",
              "      <td>2.346944</td>\n",
              "      <td>0.578078</td>\n",
              "      <td>0.536361</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>225</td>\n",
              "      <td>0.997944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>VGGA11</td>\n",
              "      <td>VGGA11_256_50</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.810604</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.811646</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>225</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VGGALRN11</td>\n",
              "      <td>VGGALRN11_256_50</td>\n",
              "      <td>0.119918</td>\n",
              "      <td>0.997717</td>\n",
              "      <td>0.117571</td>\n",
              "      <td>0.997979</td>\n",
              "      <td>0.997422</td>\n",
              "      <td>0.070891</td>\n",
              "      <td>0.583618</td>\n",
              "      <td>4.273236</td>\n",
              "      <td>0.610895</td>\n",
              "      <td>0.591530</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>225</td>\n",
              "      <td>0.997979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>VGGB13</td>\n",
              "      <td>VGGB13_256_50</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.810553</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.812170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>225</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>VGGC16</td>\n",
              "      <td>VGGC16_256_50</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.810499</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.811707</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>225</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>VGGD16</td>\n",
              "      <td>VGGD16_256_50</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.810617</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.812327</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>225</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>VGGD16Custom</td>\n",
              "      <td>VGGD16Custom_256_50</td>\n",
              "      <td>0.033011</td>\n",
              "      <td>0.964722</td>\n",
              "      <td>0.722864</td>\n",
              "      <td>0.967454</td>\n",
              "      <td>0.961893</td>\n",
              "      <td>0.012737</td>\n",
              "      <td>0.589995</td>\n",
              "      <td>2.493613</td>\n",
              "      <td>0.689342</td>\n",
              "      <td>0.573697</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>225</td>\n",
              "      <td>0.967454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>VGGE19</td>\n",
              "      <td>VGGE19_256_50</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.810546</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.812027</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>225</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>VGGE19Custom</td>\n",
              "      <td>VGGE19Custom_256_50</td>\n",
              "      <td>0.190274</td>\n",
              "      <td>0.997700</td>\n",
              "      <td>0.191680</td>\n",
              "      <td>0.997840</td>\n",
              "      <td>0.997527</td>\n",
              "      <td>0.104048</td>\n",
              "      <td>0.602323</td>\n",
              "      <td>5.310864</td>\n",
              "      <td>0.628927</td>\n",
              "      <td>0.619114</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>225</td>\n",
              "      <td>0.997840</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             name                    id  accuracy  ...  epochs  steps  precision_max\n",
              "0         DeepCNN        DeepCNN_256_50  0.043610  ...     100    225       0.994459\n",
              "1   DeepCNNCustom  DeepCNNCustom_256_50  0.040132  ...     100    225       0.986818\n",
              "2      ShallowCNN     ShallowCNN_256_50  0.071167  ...     100    225       0.997944\n",
              "3          VGGA11         VGGA11_256_50  0.000000  ...     100    225       0.000000\n",
              "4       VGGALRN11      VGGALRN11_256_50  0.119918  ...     100    225       0.997979\n",
              "5          VGGB13         VGGB13_256_50  0.000000  ...     100    225       0.000000\n",
              "6          VGGC16         VGGC16_256_50  0.000000  ...     100    225       0.000000\n",
              "7          VGGD16         VGGD16_256_50  0.000000  ...     100    225       0.000000\n",
              "8    VGGD16Custom   VGGD16Custom_256_50  0.033011  ...     100    225       0.967454\n",
              "9          VGGE19         VGGE19_256_50  0.000000  ...     100    225       0.000000\n",
              "10   VGGE19Custom   VGGE19Custom_256_50  0.190274  ...     100    225       0.997840\n",
              "\n",
              "[11 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "9BsZcpOemDbr",
        "outputId": "b717dcf7-24a6-4b47-ef18-6e7ea53a13db"
      },
      "source": [
        "df"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_metrics</th>\n",
              "      <th>loss</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_f1_metrics</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>steps</th>\n",
              "      <th>precision_max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ShallowCNN_128_30</td>\n",
              "      <td>ShallowCNN</td>\n",
              "      <td>0.007195</td>\n",
              "      <td>0.991281</td>\n",
              "      <td>0.038720</td>\n",
              "      <td>0.991945</td>\n",
              "      <td>0.990909</td>\n",
              "      <td>0.000557</td>\n",
              "      <td>0.513248</td>\n",
              "      <td>2.093277</td>\n",
              "      <td>0.548033</td>\n",
              "      <td>0.500697</td>\n",
              "      <td>128</td>\n",
              "      <td>30</td>\n",
              "      <td>225</td>\n",
              "      <td>0.997944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ShallowCNN_128_50</td>\n",
              "      <td>ShallowCNN</td>\n",
              "      <td>0.017103</td>\n",
              "      <td>0.994669</td>\n",
              "      <td>0.021875</td>\n",
              "      <td>0.994774</td>\n",
              "      <td>0.994531</td>\n",
              "      <td>0.001831</td>\n",
              "      <td>0.536337</td>\n",
              "      <td>2.116821</td>\n",
              "      <td>0.574442</td>\n",
              "      <td>0.523544</td>\n",
              "      <td>128</td>\n",
              "      <td>50</td>\n",
              "      <td>225</td>\n",
              "      <td>0.997944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ShallowCNN_128_100</td>\n",
              "      <td>ShallowCNN</td>\n",
              "      <td>0.039425</td>\n",
              "      <td>0.996770</td>\n",
              "      <td>0.009355</td>\n",
              "      <td>0.996864</td>\n",
              "      <td>0.996656</td>\n",
              "      <td>0.003662</td>\n",
              "      <td>0.549105</td>\n",
              "      <td>2.199910</td>\n",
              "      <td>0.573171</td>\n",
              "      <td>0.523823</td>\n",
              "      <td>128</td>\n",
              "      <td>100</td>\n",
              "      <td>225</td>\n",
              "      <td>0.997944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ShallowCNN_256_30</td>\n",
              "      <td>ShallowCNN</td>\n",
              "      <td>0.048910</td>\n",
              "      <td>0.997338</td>\n",
              "      <td>0.006182</td>\n",
              "      <td>0.997422</td>\n",
              "      <td>0.997213</td>\n",
              "      <td>0.004299</td>\n",
              "      <td>0.546227</td>\n",
              "      <td>2.272174</td>\n",
              "      <td>0.578078</td>\n",
              "      <td>0.536361</td>\n",
              "      <td>256</td>\n",
              "      <td>30</td>\n",
              "      <td>113</td>\n",
              "      <td>0.997944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ShallowCNN_256_50</td>\n",
              "      <td>ShallowCNN</td>\n",
              "      <td>0.057020</td>\n",
              "      <td>0.996906</td>\n",
              "      <td>0.007185</td>\n",
              "      <td>0.996934</td>\n",
              "      <td>0.996830</td>\n",
              "      <td>0.005254</td>\n",
              "      <td>0.514100</td>\n",
              "      <td>2.346944</td>\n",
              "      <td>0.560864</td>\n",
              "      <td>0.513514</td>\n",
              "      <td>256</td>\n",
              "      <td>50</td>\n",
              "      <td>113</td>\n",
              "      <td>0.997944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>VGGD16Custom_128_50</td>\n",
              "      <td>VGGD16Custom</td>\n",
              "      <td>0.005190</td>\n",
              "      <td>0.877137</td>\n",
              "      <td>0.343405</td>\n",
              "      <td>0.897089</td>\n",
              "      <td>0.858685</td>\n",
              "      <td>0.002508</td>\n",
              "      <td>0.565427</td>\n",
              "      <td>1.726418</td>\n",
              "      <td>0.620634</td>\n",
              "      <td>0.539705</td>\n",
              "      <td>128</td>\n",
              "      <td>50</td>\n",
              "      <td>225</td>\n",
              "      <td>0.967454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>VGGD16Custom_128_100</td>\n",
              "      <td>VGGD16Custom</td>\n",
              "      <td>0.013634</td>\n",
              "      <td>0.928148</td>\n",
              "      <td>0.213213</td>\n",
              "      <td>0.936293</td>\n",
              "      <td>0.920443</td>\n",
              "      <td>0.006130</td>\n",
              "      <td>0.575574</td>\n",
              "      <td>2.084198</td>\n",
              "      <td>0.609905</td>\n",
              "      <td>0.555865</td>\n",
              "      <td>128</td>\n",
              "      <td>100</td>\n",
              "      <td>225</td>\n",
              "      <td>0.967454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>VGGD16Custom_256_30</td>\n",
              "      <td>VGGD16Custom</td>\n",
              "      <td>0.022586</td>\n",
              "      <td>0.952184</td>\n",
              "      <td>0.144865</td>\n",
              "      <td>0.956832</td>\n",
              "      <td>0.948100</td>\n",
              "      <td>0.007682</td>\n",
              "      <td>0.560682</td>\n",
              "      <td>2.260318</td>\n",
              "      <td>0.603863</td>\n",
              "      <td>0.566174</td>\n",
              "      <td>256</td>\n",
              "      <td>30</td>\n",
              "      <td>113</td>\n",
              "      <td>0.967454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>VGGD16Custom_256_50</td>\n",
              "      <td>VGGD16Custom</td>\n",
              "      <td>0.024835</td>\n",
              "      <td>0.960411</td>\n",
              "      <td>0.123774</td>\n",
              "      <td>0.963728</td>\n",
              "      <td>0.956947</td>\n",
              "      <td>0.008558</td>\n",
              "      <td>0.570547</td>\n",
              "      <td>2.347999</td>\n",
              "      <td>0.617576</td>\n",
              "      <td>0.573697</td>\n",
              "      <td>256</td>\n",
              "      <td>50</td>\n",
              "      <td>113</td>\n",
              "      <td>0.967454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>VGGD16Custom_256_100</td>\n",
              "      <td>VGGD16Custom</td>\n",
              "      <td>0.033011</td>\n",
              "      <td>0.964722</td>\n",
              "      <td>0.110778</td>\n",
              "      <td>0.967454</td>\n",
              "      <td>0.961893</td>\n",
              "      <td>0.012737</td>\n",
              "      <td>0.589995</td>\n",
              "      <td>2.493613</td>\n",
              "      <td>0.605798</td>\n",
              "      <td>0.564781</td>\n",
              "      <td>256</td>\n",
              "      <td>100</td>\n",
              "      <td>113</td>\n",
              "      <td>0.967454</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>66 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id          name  accuracy  ...  epochs  steps  precision_max\n",
              "0      ShallowCNN_128_30    ShallowCNN  0.007195  ...      30    225       0.997944\n",
              "1      ShallowCNN_128_50    ShallowCNN  0.017103  ...      50    225       0.997944\n",
              "2     ShallowCNN_128_100    ShallowCNN  0.039425  ...     100    225       0.997944\n",
              "3      ShallowCNN_256_30    ShallowCNN  0.048910  ...      30    113       0.997944\n",
              "4      ShallowCNN_256_50    ShallowCNN  0.057020  ...      50    113       0.997944\n",
              "..                   ...           ...       ...  ...     ...    ...            ...\n",
              "61   VGGD16Custom_128_50  VGGD16Custom  0.005190  ...      50    225       0.967454\n",
              "62  VGGD16Custom_128_100  VGGD16Custom  0.013634  ...     100    225       0.967454\n",
              "63   VGGD16Custom_256_30  VGGD16Custom  0.022586  ...      30    113       0.967454\n",
              "64   VGGD16Custom_256_50  VGGD16Custom  0.024835  ...      50    113       0.967454\n",
              "65  VGGD16Custom_256_100  VGGD16Custom  0.033011  ...     100    113       0.967454\n",
              "\n",
              "[66 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOIj8RcnmLZq"
      },
      "source": [
        ""
      ],
      "execution_count": 89,
      "outputs": []
    }
  ]
}